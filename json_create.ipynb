{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 86,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Replace non ascii in metadata\n",
    "\n",
    "import json\n",
    "\n",
    "metadatas = json.load(open('metadata_backup.json'))\n",
    "\n",
    "ascii_replace_dict = {'â€™': '’', 'â€œ': '“', 'â€': '”', '\\u00e2\\u20ac\\u2122': '’', '\\u2019': '\\'', '\\u201d': '', '\\u201c': '', '\\u00e2\\u20ac' : '-'}\n",
    "def replace_non_ascii(s):\n",
    "    for pair_k, pair_v in ascii_replace_dict.items():\n",
    "        s = s.replace(pair_k, pair_v)\n",
    "    return s\n",
    "\n",
    "for metadata in metadatas:\n",
    "    metadata['file_url'] = replace_non_ascii(metadata['file_url'])\n",
    "    metadata['title'] = replace_non_ascii(metadata['title'])\n",
    "    if 'source' in metadata.keys() and metadata['source']:\n",
    "        metadata['source'] = replace_non_ascii(metadata['source'])\n",
    "\n",
    "import json\n",
    "with open('metadata_backup.json', 'w') as f:\n",
    "    json.dump(metadatas, f)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "metadata": {},
   "outputs": [],
   "source": [
    "files = json.load(open('all_files.json'))\n",
    "all_filenames = [file['filename'].rsplit(\".\",1)[0] for file in files['data'] if file['filename'].split('.')[-1] == \"docx\"]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 104,
   "metadata": {},
   "outputs": [],
   "source": [
    "all_filenames = [replace_non_ascii(f) for f in all_filenames]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 61,
   "metadata": {},
   "outputs": [],
   "source": [
    "asst_file = json.load(open('asst_file.json'))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 105,
   "metadata": {},
   "outputs": [],
   "source": [
    "metadatas = json.load(open('metadata_backup.json'))\n",
    "\n",
    "for metadata in metadatas:\n",
    "    file_url = metadata['file_url'].rsplit('.', 1)[0]\n",
    "    title = metadata['title']\n",
    "    if file_url in all_filenames or title in all_filenames:\n",
    "        idx = None\n",
    "        if file_url in all_filenames:\n",
    "            idx = all_filenames.index(file_url)\n",
    "        elif title in all_filenames:\n",
    "            idx = all_filenames.index(title)\n",
    "        file_OAI_id = files['data'][idx]['id']\n",
    "        # print(file_OAI_id)\n",
    "        # print(next(pair for pair in asst_file if pair['file_id'] == file_OAI_id))\n",
    "        metadata['file_OAI_id'] = files['data'][idx]['id']\n",
    "        metadata['assistant_OAI_id'] = next(pair for pair in asst_file if pair['file_id'] == file_OAI_id)['assistant_id']\n",
    "    else:\n",
    "        print(file_url)\n",
    "        print(title)\n",
    "        raise RuntimeError('File not found!')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 106,
   "metadata": {},
   "outputs": [],
   "source": [
    "with open('metadata.json', 'w') as f:\n",
    "    json.dump(metadatas, f)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "base",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.9"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
