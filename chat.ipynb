{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "from langchain.chat_models import ChatOpenAI\n",
    "\n",
    "llm_name = \"gpt-3.5-turbo\"\n",
    "llm = ChatOpenAI(model_name = llm_name, temperature = 0)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Vectorstore loading\n",
    "\n",
    "from langchain.vectorstores import Chroma\n",
    "from langchain.embeddings import OpenAIEmbeddings\n",
    "\n",
    "embeddings = OpenAIEmbeddings()\n",
    "\n",
    "vectorstore = Chroma(persist_directory=\"./chroma_db\", embedding_function = embeddings)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from langchain.chains.query_constructor.base import AttributeInfo\n",
    "from langchain.retrievers.self_query.base import SelfQueryRetriever\n",
    "\n",
    "\n",
    "# TODO: add new metadata\n",
    "metadata_field_info = [\n",
    "    AttributeInfo(\n",
    "        name=\"document_name\",\n",
    "        description=\"Name of the source document\",\n",
    "        type=\"string\",\n",
    "    ),\n",
    "    AttributeInfo(\n",
    "        name=\"id\",\n",
    "        description=\"Document ID\",\n",
    "        type=\"string\",\n",
    "    ),\n",
    "    AttributeInfo(\n",
    "        name=\"title\",\n",
    "        description=\"Title of the document\",\n",
    "        type=\"string\",\n",
    "    ),\n",
    "    AttributeInfo(\n",
    "        name=\"date\",\n",
    "        description=\"When the document was created\",\n",
    "        type=\"string\",\n",
    "    ),\n",
    "    AttributeInfo(\n",
    "        name=\"register_num\",\n",
    "        description=\"Patent registration number\",\n",
    "        type=\"string\",\n",
    "    ),\n",
    "    AttributeInfo(\n",
    "        name=\"source\",\n",
    "        description=\"Source of the document\",\n",
    "        type=\"string\",\n",
    "    ),\n",
    "    AttributeInfo(\n",
    "        name=\"type\",\n",
    "        description=\"Type of the document - options are lecture, article, patent\",\n",
    "        type=\"string\",\n",
    "    )\n",
    "]\n",
    "\n",
    "document_content_description = \"Document content\"\n",
    "\n",
    "retriever = SelfQueryRetriever.from_llm(\n",
    "    llm = llm, \n",
    "    vectorstore = vectorstore,\n",
    "    document_contents = document_content_description,\n",
    "    metadata_field_info = metadata_field_info, \n",
    "    verbose=True\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/jaksa/miniconda3/lib/python3.10/site-packages/langchain/chains/llm.py:278: UserWarning: The predict_and_parse method is deprecated, instead pass an output parser directly to LLMChain.\n",
      "  warnings.warn(\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "query='Nikola Tesla' filter=Comparison(comparator=<Comparator.EQ: 'eq'>, attribute='type', value='lecture') limit=None\n"
     ]
    }
   ],
   "source": [
    "docs = retriever.get_relevant_documents(\"What lectures did Nikola Tesla give\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['On Light and Other High Frequency Phenomena.docx',\n",
       " 'Experiments With Alternate Currents of High Potential and High Frequency (lecture).docx',\n",
       " 'A New System of Alternate Current Motors and Transformers (lecture).docx',\n",
       " '8 High Frequency Oscillators for Electro-Therapeutic and Other Purposes (lecture).docx']"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "[d.metadata['filename'] for d in docs]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "query='electromotor poles' filter=None limit=None\n",
      "{'query': 'How many poles shoul my electromotor have, and what should I do if I have the wrong number?', 'result': 'Based on the given context, the number of poles in an electromotor can vary. The motor X has eight poles, the motor Y has six poles, and the motor Z has four poles. The number of poles determines the speed of the motor. If you have the wrong number of poles, you can change the electrical connections to achieve the desired speed. For example, in motor X, you can alternate between two like and two opposite poles to effectively reduce the number of poles by half and double the speed of the motor.'}\n"
     ]
    }
   ],
   "source": [
    "# Basic Retriever example\n",
    "\n",
    "from langchain.chains import RetrievalQA\n",
    "\n",
    "question = \"How many poles shoul my electromotor have, and what should I do if I have the wrong number?\"\n",
    "qa_chain = RetrievalQA.from_chain_type(llm = llm, retriever = retriever)\n",
    "print(qa_chain({\"query\": question}))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Retriever with memory example\n",
    "\n",
    "from langchain.memory import ConversationBufferMemory\n",
    "from langchain.chains import ConversationalRetrievalChain\n",
    "\n",
    "memory = ConversationBufferMemory(memory_key = \"chat_history\", return_messages = True)\n",
    "retriever = vectorstore.as_retriever()\n",
    "qa = ConversationalRetrievalChain.from_llm(llm = llm, retriever = retriever, memory = memory)\n",
    "question = input()\n",
    "print(f\"Question: {question}\")\n",
    "print(f\"Answer: {qa({'question': question})['answer']}\")\n",
    "question = input()\n",
    "print(f\"Question: {question}\")\n",
    "print(f\"Answer: {qa({'question': question})['answer']}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "q = \"\"\"Use the following pieces of context to answer the question at the end.\n",
    "If you don't know the answer, just say that you don't know, don't try to\n",
    "make up an answer.\n",
    "\n",
    "{context} // i.e the pdf text content\n",
    "\n",
    "Question: {query} // i.e our actualy query, 'Who is the CV about?'\n",
    "Helpful Answer:\"\"\""
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "base",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.9"
  },
  "orig_nbformat": 4
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
