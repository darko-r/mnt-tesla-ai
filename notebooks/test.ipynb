{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "# LLM loading\n",
    "\n",
    "from langchain.chat_models import ChatOpenAI\n",
    "\n",
    "llm_name = \"gpt-3.5-turbo\"\n",
    "llm = ChatOpenAI(model_name = llm_name, temperature = 0)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Vectorstore loading\n",
    "\n",
    "from langchain.vectorstores import Chroma\n",
    "from langchain.embeddings import OpenAIEmbeddings\n",
    "\n",
    "embeddings = OpenAIEmbeddings()\n",
    "\n",
    "vectorstore = Chroma(persist_directory=f\"./vectorstore_nltk\", embedding_function = embeddings)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "# BaseRetriever\n",
    "\n",
    "from langchain.retrievers import ContextualCompressionRetriever\n",
    "\n",
    "base_retriever = vectorstore.as_retriever(search_type = 'mmr', search_kwargs = {'k': 2})"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "# MultiQueryRetriever\n",
    "\n",
    "from langchain.retrievers.multi_query import MultiQueryRetriever\n",
    "\n",
    "multi_query = MultiQueryRetriever.from_llm(retriever = base_retriever, llm = llm)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "# SelfQueryRetriever\n",
    "\n",
    "from langchain.chains.query_constructor.base import AttributeInfo\n",
    "from langchain.retrievers.self_query.base import SelfQueryRetriever\n",
    "\n",
    "metadata_field_info = [\n",
    "    AttributeInfo(\n",
    "        name=\"category\",\n",
    "        description=\"Category of te text content - possible values are NarrativeText and Title\",\n",
    "        type=\"string\",\n",
    "    ),\n",
    "    AttributeInfo(\n",
    "        name=\"year\",\n",
    "        description=\"Year when the document was published\",\n",
    "        type=\"integer\",\n",
    "    ),\n",
    "    AttributeInfo(\n",
    "        name=\"applicant\",\n",
    "        description=\"Name of the person that filed the patent\",\n",
    "        type=\"string\",\n",
    "    ),\n",
    "    AttributeInfo(\n",
    "        name=\"day\",\n",
    "        description=\"Day when the document was published\",\n",
    "        type=\"integer\",\n",
    "    ),\n",
    "    AttributeInfo(\n",
    "        name=\"month\",\n",
    "        description=\"Month when the document was published\",\n",
    "        type=\"integer\",\n",
    "    ),\n",
    "    AttributeInfo(\n",
    "        name=\"filename\",\n",
    "        description=\"Name of the file\",\n",
    "        type=\"string\",\n",
    "    ),\n",
    "    AttributeInfo(\n",
    "        name=\"id\",\n",
    "        description=\"Document ID\",\n",
    "        type=\"string\",\n",
    "    ),\n",
    "    AttributeInfo(\n",
    "        name=\"page_number\",\n",
    "        description=\"Page number from the original document\",\n",
    "        type=\"string\",\n",
    "    ),\n",
    "    AttributeInfo(\n",
    "        name=\"register_num\",\n",
    "        description=\"Patent registration number\",\n",
    "        type=\"string\",\n",
    "    ),\n",
    "    AttributeInfo(\n",
    "        name=\"source\",\n",
    "        description=\"Source that published the document.\",\n",
    "        type=\"string\",\n",
    "    ),\n",
    "    AttributeInfo(\n",
    "        name=\"title\",\n",
    "        description=\"Document title\",\n",
    "        type=\"string\",\n",
    "    ),\n",
    "    AttributeInfo(\n",
    "        name=\"type\",\n",
    "        description=\"Type of the document - possible value are article, lecture and patent\",\n",
    "        type=\"string\",\n",
    "    ),\n",
    "]\n",
    "\n",
    "document_content_description = \"Document content\"\n",
    "\n",
    "self_query_retriever = SelfQueryRetriever.from_llm(llm = llm, vectorstore = vectorstore, document_contents = document_content_description,\n",
    "                                                   metadata_field_info = metadata_field_info, verbose=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "# EnsembleRetriever\n",
    "\n",
    "from langchain.retrievers import EnsembleRetriever\n",
    "\n",
    "ensemble_retriever = EnsembleRetriever(retrievers = [multi_query, self_query_retriever])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Prompt template\n",
    "\n",
    "from langchain import PromptTemplate\n",
    "\n",
    "prompt_template = PromptTemplate.from_template(\n",
    "    \"\"\"Let's think step by step. Use the following pieces of context to answer the question at the end.\n",
    "    If you don't know the answer, just say that you don't know, don't try to\n",
    "    make up an answer.\n",
    "\n",
    "    Context:\n",
    "    {context}\n",
    "\n",
    "    Question: {question}\n",
    "    Helpful Answer:\"\"\"\n",
    ")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Chain definition\n",
    "\n",
    "from langchain.memory import ConversationBufferMemory\n",
    "from langchain.chains import ConversationalRetrievalChain\n",
    "\n",
    "memory = ConversationBufferMemory(\n",
    "    memory_key=\"chat_history\",\n",
    "    return_messages=True\n",
    ")\n",
    "chain = ConversationalRetrievalChain.from_llm(llm = llm, \n",
    "                                              retriever = ensemble_retriever, \n",
    "                                              chain_type = 'map_reduce',\n",
    "                                              memory = memory)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/jaksa/miniconda3/lib/python3.10/site-packages/langchain/chains/llm.py:278: UserWarning: The predict_and_parse method is deprecated, instead pass an output parser directly to LLMChain.\n",
      "  warnings.warn(\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "query='Nikola Tesla Mars' filter=None limit=None\n",
      "query=' ' filter=Operation(operator=<Operator.AND: 'and'>, arguments=[Comparison(comparator=<Comparator.EQ: 'eq'>, attribute='applicant', value='Nikola Tesla'), Comparison(comparator=<Comparator.GTE: 'gte'>, attribute='year', value=1890), Comparison(comparator=<Comparator.LTE: 'lte'>, attribute='year', value=1895), Comparison(comparator=<Comparator.EQ: 'eq'>, attribute='type', value='patent')]) limit=None\n",
      "query='Nikola Tesla vision future travel' filter=Comparison(comparator=<Comparator.EQ: 'eq'>, attribute='applicant', value='Nikola Tesla') limit=None\n",
      "query='human eye' filter=Comparison(comparator=<Comparator.EQ: 'eq'>, attribute='applicant', value='Nikola Tesla') limit=None\n",
      "query='Nikola Tesla' filter=Comparison(comparator=<Comparator.EQ: 'eq'>, attribute='title', value='Birth') limit=None\n"
     ]
    }
   ],
   "source": [
    "# Test\n",
    "\n",
    "import datetime\n",
    "\n",
    "file_name = f\"responses/responses_{str(datetime.datetime.now()).replace(' ', '_').replace(':', '_')}.txt\"\n",
    "queries = [\"What did Nikola Tesla think about Mars?\",\n",
    "           \"How many patents did Nikola Tesla file between 1890. and 1895.?\",\n",
    "           \"How did Nikola Tesla envision the future of travel?\",\n",
    "           \"What is Tesla's description of the human eye?\",\n",
    "           \"Where was Nikola Tesla born?\"]\n",
    "\n",
    "with open(file_name, 'w') as file:\n",
    "    file.write(f\"{str(datetime.datetime.now())}\\n\\n\")\n",
    "\n",
    "for q in queries:\n",
    "    with open(file_name, 'a') as file:\n",
    "        file.write(f\"- Query: {q}\\n\")\n",
    "        file.write(f\"   - Split: nltk\\n\")\n",
    "        file.write(f\"      - Retriever: ensemble\\n\")\n",
    "        try:\n",
    "            file.write(f\"         - Response: {chain.run(q)}\\n\")\n",
    "        except Exception as e:\n",
    "            file.write(f\"         - ERROR: {e}\\n\")\n",
    "        file.write(f\"\\n\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "base",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.9"
  },
  "orig_nbformat": 4
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
