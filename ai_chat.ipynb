{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Elements loader\n",
    "\n",
    "from langchain.document_loaders import UnstructuredWordDocumentLoader\n",
    "from langchain.document_loaders import DirectoryLoader\n",
    "\n",
    "elements_loader = DirectoryLoader(path = \"docx_docs\", \n",
    "                                  loader_cls = UnstructuredWordDocumentLoader,\n",
    "                                  loader_kwargs = {'mode' : \"elements\", 'strategy': \"fast\"},\n",
    "                                  recursive = True)\n",
    "\n",
    "docs_elements = elements_loader.load()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Recursive loaders\n",
    "\n",
    "from langchain.text_splitter import RecursiveCharacterTextSplitter\n",
    "from langchain.document_loaders import UnstructuredWordDocumentLoader\n",
    "from langchain.document_loaders import DirectoryLoader\n",
    "\n",
    "single_loader = DirectoryLoader(path = \"docx_docs\", \n",
    "                                loader_cls = UnstructuredWordDocumentLoader,\n",
    "                                loader_kwargs = {'mode' : \"single\", 'strategy': \"fast\"},\n",
    "                                recursive = True)\n",
    "docs_single = single_loader.load()\n",
    "\n",
    "text_splitter = RecursiveCharacterTextSplitter(chunk_size = 2000, chunk_overlap  = 0, separators = [\"\\n\\n\", \"(?<=\\n)\", \"(?<=\\. )\"], is_separator_regex = True)\n",
    "child_text_splitter = RecursiveCharacterTextSplitter(chunk_size = 500, chunk_overlap  = 0, separators = [\"\\n\\n\", \"(?<=\\n)\", \"(?<=\\. )\"], is_separator_regex = True)\n",
    "\n",
    "docs_recursive = text_splitter.split_documents(docs_single)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "# NLTK loader\n",
    "from langchain.text_splitter import NLTKTextSplitter\n",
    "\n",
    "nltk_splitter = NLTKTextSplitter()\n",
    "\n",
    "docs_nltk = nltk_splitter.split_documents(docs_single)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Finename metadata rename \n",
    "\n",
    "for doc in docs_nltk:\n",
    "    doc.metadata['filename'] = doc.metadata['source'].split('/')[-1]\n",
    "    del doc.metadata['source']\n",
    "\n",
    "for doc in docs_recursive:\n",
    "    doc.metadata['filename'] = doc.metadata['source'].split('/')[-1]\n",
    "    del doc.metadata['source']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Remove undeeded metadata from Elements documents\n",
    "\n",
    "keys_to_delete = ['source', 'file_directory', 'last_modified', 'filetype', 'primary', 'text_as_html', 'emphasized_text_tags', 'emphasized_text_contents']\n",
    "\n",
    "for doc in docs_elements:\n",
    "    for key in keys_to_delete:\n",
    "        if key in doc.metadata.keys():\n",
    "            del doc.metadata[key]\n",
    "\n",
    "# Removing unneeded documents\n",
    "categories_to_remove = ['PageBreak', 'ListItem', 'Footer', 'Table', 'UncategorizedText', 'Header']\n",
    "docs_elements = [doc for doc in docs_elements if doc.metadata['category'] not in categories_to_remove]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 54,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Plots\n",
    "\n",
    "# from matplotlib import pyplot as plt\n",
    "\n",
    "# plt.figure(1)\n",
    "# plt.hist([len(d.page_content) for d in docs_nltk], bins = 100)\n",
    "# plt.grid()\n",
    "# plt.title(\"NLTK документи\")\n",
    "# plt.xlabel(\"број карактера у документу\")\n",
    "# plt.ylabel(\"број докумената\")\n",
    "# plt.figure(2)\n",
    "# plt.hist([len(d.page_content) for d in docs_elements], bins = 100)\n",
    "# plt.grid()\n",
    "# plt.title(\"Elements documents\")\n",
    "# plt.xlabel(\"број карактера у документу\")\n",
    "# plt.ylabel(\"број докумената\")\n",
    "# plt.figure(3)\n",
    "# plt.hist([len(d.page_content) for d in docs_recursive], bins = 100)\n",
    "# plt.grid()\n",
    "# plt.title(\"Recursive documents\")\n",
    "# plt.xlabel(\"број карактера у документу\")\n",
    "# plt.ylabel(\"број докумената\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Metadata parsing\n",
    "\n",
    "import json\n",
    "\n",
    "metadata_dict = {}\n",
    "metadatas = json.load(open('metadata.json'))\n",
    "\n",
    "ascii_replace_dict = {'â€™': '’', 'â€œ': '“', 'â€': '”'}\n",
    "def replace_non_ascii(s):\n",
    "    for pair_k, pair_v in ascii_replace_dict.items():\n",
    "        s = s.replace(pair_k, pair_v)\n",
    "    return s\n",
    "\n",
    "for metadata in metadatas[2]['data']:\n",
    "    if metadata['id'] in ['228', '413']:\n",
    "        # These are duplicates, not needed\n",
    "        continue\n",
    "    key = ''.join(metadata['file_url'].split('/')[-1].rsplit('.', 1)[:-1])\n",
    "\n",
    "    # Repalce non-ascii characters in key\n",
    "    key = replace_non_ascii(key)\n",
    "    \n",
    "    # Make sure that there are no duplicate entries for the same document type\n",
    "    if (key in metadata_dict.keys() and metadata['type'] == metadata_dict[key]['type']):\n",
    "        print(key)\n",
    "        print(metadata['id'])\n",
    "    assert not (key in metadata_dict.keys() and metadata['type'] == metadata_dict[key]['type'])\n",
    "    metadata_dict[key] = {key: value for key, value in metadata.items() if value is not None}\n",
    "    \n",
    "    # Replace non-ascii characters in file url\n",
    "    del metadata_dict[key]['file_url']\n",
    "    for m_key, m_value in metadata_dict.items():\n",
    "        if m_value is None:\n",
    "            del metadata_dict[m_key]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Adding metadata\n",
    "\n",
    "for doc in docs_elements:\n",
    "    assert doc.metadata['filename'][:-5] in metadata_dict.keys()\n",
    "    doc.metadata.update(metadata_dict[doc.metadata['filename'][:-5]])\n",
    "\n",
    "for doc in docs_nltk:\n",
    "    assert doc.metadata['filename'][:-5] in metadata_dict.keys()\n",
    "    doc.metadata.update(metadata_dict[doc.metadata['filename'][:-5]])\n",
    "\n",
    "for doc in docs_recursive:\n",
    "    assert doc.metadata['filename'][:-5] in metadata_dict.keys()\n",
    "    doc.metadata.update(metadata_dict[doc.metadata['filename'][:-5]])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 121,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Summary document\n",
    "\n",
    "file_path = 'summary.txt'\n",
    "\n",
    "with open(file_path, 'w') as file:\n",
    "    file.write('This file is a summary document of all of the articles, lectures and patents\\n')\n",
    "    file.write('\\nArticles:\\n')\n",
    "    file.write('\\nLectures:\\n')\n",
    "    file.write('\\nPatents:\\n')\n",
    "\n",
    "a_num = 0\n",
    "l_num = 0\n",
    "p_num = 0\n",
    "\n",
    "for metadata_key in metadata_dict.keys():\n",
    "    with open(file_path, 'r') as file:\n",
    "        lines = file.readlines()\n",
    "\n",
    "    new_lines = []\n",
    "\n",
    "    a_num += 1 if metadata_dict[metadata_key]['type'] == 'article' else 0\n",
    "    l_num += 1 if metadata_dict[metadata_key]['type'] == 'lecture' else 0\n",
    "    p_num += 1 if metadata_dict[metadata_key]['type'] == 'patent' else 0\n",
    "\n",
    "    for i, line in enumerate(lines):\n",
    "        new_lines.append(line)\n",
    "        \n",
    "        if metadata_dict[metadata_key]['type'] == 'article':\n",
    "            if 'Articles:' in line:\n",
    "                new_line = f\"    - Article {metadata_dict[metadata_key]['title']} written in {metadata_dict[metadata_key]['date']} published by {metadata_dict[metadata_key]['source']}\\n\"\n",
    "                new_lines.append(new_line)\n",
    "        \n",
    "        if metadata_dict[metadata_key]['type'] == 'lecture':\n",
    "            if 'Lectures:' in line:\n",
    "                new_line = f\"    - Lecture {metadata_dict[metadata_key]['title']} held in {metadata_dict[metadata_key]['date']}\\n\"\n",
    "                new_lines.append(new_line)\n",
    "        \n",
    "        if metadata_dict[metadata_key]['type'] == 'patent':\n",
    "            if 'Patents:' in line:\n",
    "                new_line = f\"    - Patent {metadata_dict[metadata_key]['title']} filed in {metadata_dict[metadata_key]['date']} with registration number {metadata_dict[metadata_key]['register_num']}\\n\"\n",
    "                new_lines.append(new_line)\n",
    "\n",
    "\n",
    "    with open(file_path, 'w') as file:\n",
    "        file.writelines(new_lines)\n",
    "\n",
    "    \n",
    "with open(file_path, 'r') as file:\n",
    "    lines = file.readlines()\n",
    "new_lines = []\n",
    "for i, line in enumerate(lines):\n",
    "    if 'Patents:' in line:\n",
    "        new_lines.append(f\"Patents ({p_num} files):\\n\")\n",
    "    elif 'Articles:' in line:\n",
    "        new_lines.append(f\"Articles ({a_num} files):\\n\")\n",
    "    elif 'Lectures:' in line:\n",
    "        new_lines.append(f\"Lectures ({l_num} files):\\n\")\n",
    "    else:\n",
    "        new_lines.append(line)\n",
    "with open(file_path, 'w') as file:\n",
    "    file.writelines(new_lines)\n",
    "\n",
    "from langchain.document_loaders import TextLoader\n",
    "\n",
    "doc = TextLoader(file_path).load()\n",
    "\n",
    "docs_metadata = text_splitter.split_documents(doc)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Vectorstore creation\n",
    "\n",
    "from langchain.vectorstores import Chroma\n",
    "from langchain.embeddings import OpenAIEmbeddings\n",
    "\n",
    "embeddings = OpenAIEmbeddings()\n",
    "\n",
    "# vectorstore_elements = Chroma.from_documents(\n",
    "#     collection_name=\"elements\",\n",
    "#     documents = docs_elements + docs_metadata,\n",
    "#     embedding = embeddings,\n",
    "#     persist_directory=\"./vectorstore_elements\"\n",
    "# )\n",
    "\n",
    "# vectorstore_nltk = Chroma.from_documents(\n",
    "#     collection_name=\"nltk\",\n",
    "#     documents = docs_nltk + docs_metadata,\n",
    "#     embedding = embeddings,\n",
    "#     persist_directory=\"./vectorstore_nltk\"\n",
    "# )\n",
    "\n",
    "# vectorstore_recursive = Chroma.from_documents(\n",
    "#     collection_name=\"recursive\",\n",
    "#     documents = docs_recursive + docs_metadata,\n",
    "#     embedding = embeddings,\n",
    "#     persist_directory=\"./vectorstore_recursive\"\n",
    "# )"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "# LLM loading\n",
    "\n",
    "from langchain.chat_models import ChatOpenAI\n",
    "\n",
    "llm_name = \"gpt-3.5-turbo\"\n",
    "llm = ChatOpenAI(model_name = llm_name, temperature = 0)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Vectorstore loading\n",
    "\n",
    "from langchain.vectorstores import Chroma\n",
    "from langchain.embeddings import OpenAIEmbeddings\n",
    "\n",
    "embeddings = OpenAIEmbeddings()\n",
    "\n",
    "names = ['elements', 'nltk', 'recursive']\n",
    "all_bases = {}\n",
    "all_retrievers = {}\n",
    "\n",
    "for name in names:\n",
    "    all_bases[name] = Chroma(persist_directory=f\"./vectorstore_{name}\", embedding_function = embeddings)\n",
    "    all_retrievers[name] = {}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [],
   "source": [
    "# BaseRetriever\n",
    "\n",
    "for name in names:\n",
    "    all_retrievers[name]['base'] = all_bases[name].as_retriever(search_type = 'mmr', \n",
    "                                                                search_kwargs = {'k': 3})"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [],
   "source": [
    "# MultiQueryRetriever\n",
    "\n",
    "from langchain.retrievers.multi_query import MultiQueryRetriever\n",
    "\n",
    "for name in names:\n",
    "    all_retrievers[name]['multi_query'] = MultiQueryRetriever.from_llm(retriever = all_bases[name].as_retriever(search_type = 'mmr'), \n",
    "                                                                       llm = llm)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [],
   "source": [
    "# ContextualCompressionRetriever\n",
    "\n",
    "from langchain.retrievers import ContextualCompressionRetriever\n",
    "from langchain.retrievers.document_compressors import LLMChainExtractor\n",
    "\n",
    "for name in names:\n",
    "    compressor = LLMChainExtractor.from_llm(llm)\n",
    "    all_retrievers[name]['compression_retriever'] = ContextualCompressionRetriever(base_compressor = compressor, \n",
    "                                                                                   base_retriever = all_retrievers[name]['base'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [],
   "source": [
    "# SelfQueryRetriever\n",
    "\n",
    "from langchain.chains.query_constructor.base import AttributeInfo\n",
    "from langchain.retrievers.self_query.base import SelfQueryRetriever\n",
    "\n",
    "metadata_field_info = [\n",
    "    AttributeInfo(\n",
    "        name=\"category\",\n",
    "        description=\"Category of te text content - possible values are NarrativeText and Title\",\n",
    "        type=\"string\",\n",
    "    ),\n",
    "    AttributeInfo(\n",
    "        name=\"date\",\n",
    "        description=\"Date when the document was published\",\n",
    "        type=\"string\",\n",
    "    ),\n",
    "    AttributeInfo(\n",
    "        name=\"filename\",\n",
    "        description=\"Name of the file\",\n",
    "        type=\"string\",\n",
    "    ),\n",
    "    AttributeInfo(\n",
    "        name=\"id\",\n",
    "        description=\"Document ID\",\n",
    "        type=\"string\",\n",
    "    ),\n",
    "    AttributeInfo(\n",
    "        name=\"page_number\",\n",
    "        description=\"Page number from the original document\",\n",
    "        type=\"string\",\n",
    "    ),\n",
    "    AttributeInfo(\n",
    "        name=\"register_num\",\n",
    "        description=\"Patent registration number\",\n",
    "        type=\"string\",\n",
    "    ),\n",
    "    AttributeInfo(\n",
    "        name=\"source\",\n",
    "        description=\"Source that published the document\",\n",
    "        type=\"string\",\n",
    "    ),\n",
    "    AttributeInfo(\n",
    "        name=\"title\",\n",
    "        description=\"Document title\",\n",
    "        type=\"string\",\n",
    "    ),\n",
    "    AttributeInfo(\n",
    "        name=\"type\",\n",
    "        description=\"Type of the document - possible value are article, lecture and patent\",\n",
    "        type=\"string\",\n",
    "    ),\n",
    "]\n",
    "\n",
    "document_content_description = \"Document content\"\n",
    "\n",
    "for name in names:\n",
    "    compressor = LLMChainExtractor.from_llm(llm)\n",
    "    all_retrievers[name]['self_query_retriever'] = SelfQueryRetriever.from_llm(llm = llm, \n",
    "                                                                               vectorstore = all_bases[name],\n",
    "                                                                               document_contents = document_content_description,\n",
    "                                                                               metadata_field_info = metadata_field_info, \n",
    "                                                                               verbose=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [],
   "source": [
    "# EnsembleRetriever\n",
    "\n",
    "from langchain.retrievers import EnsembleRetriever\n",
    "\n",
    "for name in names:\n",
    "    all_retrievers[name]['ensemble_retriever'] = EnsembleRetriever(retrievers = [r for r in all_retrievers[name].values()])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'elements': {'base': VectorStoreRetriever(tags=['Chroma', 'OpenAIEmbeddings'], metadata=None, vectorstore=<langchain.vectorstores.chroma.Chroma object at 0x7fd6978c46d0>, search_type='mmr', search_kwargs={}),\n",
       "  'multi_query': MultiQueryRetriever(tags=None, metadata=None, retriever=VectorStoreRetriever(tags=['Chroma', 'OpenAIEmbeddings'], metadata=None, vectorstore=<langchain.vectorstores.chroma.Chroma object at 0x7fd6978c46d0>, search_type='mmr', search_kwargs={}), llm_chain=LLMChain(memory=None, callbacks=None, callback_manager=None, verbose=False, tags=None, metadata=None, prompt=PromptTemplate(input_variables=['question'], output_parser=None, partial_variables={}, template='You are an AI language model assistant. Your task is \\n    to generate 3 different versions of the given user \\n    question to retrieve relevant documents from a vector  database. \\n    By generating multiple perspectives on the user question, \\n    your goal is to help the user overcome some of the limitations \\n    of distance-based similarity search. Provide these alternative \\n    questions separated by newlines. Original question: {question}', template_format='f-string', validate_template=True), llm=ChatOpenAI(cache=None, verbose=False, callbacks=None, callback_manager=None, tags=None, metadata=None, client=<class 'openai.api_resources.chat_completion.ChatCompletion'>, model_name='gpt-3.5-turbo', temperature=0.0, model_kwargs={}, openai_api_key='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', openai_api_base='', openai_organization='', openai_proxy='', request_timeout=None, max_retries=6, streaming=False, n=1, max_tokens=None, tiktoken_model_name=None), output_key='text', output_parser=LineListOutputParser(pydantic_object=<class 'langchain.retrievers.multi_query.LineList'>), return_final_only=True, llm_kwargs={}), verbose=True, parser_key='lines'),\n",
       "  'compression_retriever': ContextualCompressionRetriever(tags=None, metadata=None, base_compressor=LLMChainExtractor(llm_chain=LLMChain(memory=None, callbacks=None, callback_manager=None, verbose=False, tags=None, metadata=None, prompt=PromptTemplate(input_variables=['question', 'context'], output_parser=NoOutputParser(no_output_str='NO_OUTPUT'), partial_variables={}, template='Given the following question and context, extract any part of the context *AS IS* that is relevant to answer the question. If none of the context is relevant return NO_OUTPUT. \\n\\nRemember, *DO NOT* edit the extracted parts of the context.\\n\\n> Question: {question}\\n> Context:\\n>>>\\n{context}\\n>>>\\nExtracted relevant parts:', template_format='f-string', validate_template=True), llm=ChatOpenAI(cache=None, verbose=False, callbacks=None, callback_manager=None, tags=None, metadata=None, client=<class 'openai.api_resources.chat_completion.ChatCompletion'>, model_name='gpt-3.5-turbo', temperature=0.0, model_kwargs={}, openai_api_key='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', openai_api_base='', openai_organization='', openai_proxy='', request_timeout=None, max_retries=6, streaming=False, n=1, max_tokens=None, tiktoken_model_name=None), output_key='text', output_parser=StrOutputParser(), return_final_only=True, llm_kwargs={}), get_input=<function default_get_input at 0x7fd6ed1bb910>), base_retriever=VectorStoreRetriever(tags=['Chroma', 'OpenAIEmbeddings'], metadata=None, vectorstore=<langchain.vectorstores.chroma.Chroma object at 0x7fd6978c46d0>, search_type='mmr', search_kwargs={})),\n",
       "  'self_query_retriever': SelfQueryRetriever(tags=None, metadata=None, vectorstore=<langchain.vectorstores.chroma.Chroma object at 0x7fd6978c46d0>, llm_chain=LLMChain(memory=None, callbacks=None, callback_manager=None, verbose=False, tags=None, metadata=None, prompt=FewShotPromptTemplate(input_variables=['query'], output_parser=StructuredQueryOutputParser(ast_parse=<bound method Lark.parse of Lark(open('<string>'), parser='lalr', lexer='contextual', ...)>), partial_variables={}, examples=[{'i': 1, 'data_source': '```json\\n{{\\n    \"content\": \"Lyrics of a song\",\\n    \"attributes\": {{\\n        \"artist\": {{\\n            \"type\": \"string\",\\n            \"description\": \"Name of the song artist\"\\n        }},\\n        \"length\": {{\\n            \"type\": \"integer\",\\n            \"description\": \"Length of the song in seconds\"\\n        }},\\n        \"genre\": {{\\n            \"type\": \"string\",\\n            \"description\": \"The song genre, one of \"pop\", \"rock\" or \"rap\"\"\\n        }}\\n    }}\\n}}\\n```', 'user_query': 'What are songs by Taylor Swift or Katy Perry about teenage romance under 3 minutes long in the dance pop genre', 'structured_request': '```json\\n{{\\n    \"query\": \"teenager love\",\\n    \"filter\": \"and(or(eq(\\\\\"artist\\\\\", \\\\\"Taylor Swift\\\\\"), eq(\\\\\"artist\\\\\", \\\\\"Katy Perry\\\\\")), lt(\\\\\"length\\\\\", 180), eq(\\\\\"genre\\\\\", \\\\\"pop\\\\\"))\"\\n}}\\n```'}, {'i': 2, 'data_source': '```json\\n{{\\n    \"content\": \"Lyrics of a song\",\\n    \"attributes\": {{\\n        \"artist\": {{\\n            \"type\": \"string\",\\n            \"description\": \"Name of the song artist\"\\n        }},\\n        \"length\": {{\\n            \"type\": \"integer\",\\n            \"description\": \"Length of the song in seconds\"\\n        }},\\n        \"genre\": {{\\n            \"type\": \"string\",\\n            \"description\": \"The song genre, one of \"pop\", \"rock\" or \"rap\"\"\\n        }}\\n    }}\\n}}\\n```', 'user_query': 'What are songs that were not published on Spotify', 'structured_request': '```json\\n{{\\n    \"query\": \"\",\\n    \"filter\": \"NO_FILTER\"\\n}}\\n```'}], example_selector=None, validate_template=True, example_prompt=PromptTemplate(input_variables=['i', 'data_source', 'user_query', 'structured_request'], output_parser=None, partial_variables={}, template='<< Example {i}. >>\\nData Source:\\n{data_source}\\n\\nUser Query:\\n{user_query}\\n\\nStructured Request:\\n{structured_request}\\n', template_format='f-string', validate_template=True), suffix='<< Example 3. >>\\nData Source:\\n```json\\n{{\\n    \"content\": \"Document content\",\\n    \"attributes\": {{\\n    \"category\": {{\\n        \"description\": \"Category of te text content - possible values are NarrativeText and Title\",\\n        \"type\": \"string\"\\n    }},\\n    \"date\": {{\\n        \"description\": \"Date when the document was published\",\\n        \"type\": \"string\"\\n    }},\\n    \"filename\": {{\\n        \"description\": \"Name of the file\",\\n        \"type\": \"string\"\\n    }},\\n    \"id\": {{\\n        \"description\": \"Document ID\",\\n        \"type\": \"string\"\\n    }},\\n    \"page_number\": {{\\n        \"description\": \"Page number from the original document\",\\n        \"type\": \"string\"\\n    }},\\n    \"register_num\": {{\\n        \"description\": \"Patent registration number\",\\n        \"type\": \"string\"\\n    }},\\n    \"source\": {{\\n        \"description\": \"Source that published the document\",\\n        \"type\": \"string\"\\n    }},\\n    \"title\": {{\\n        \"description\": \"Document title\",\\n        \"type\": \"string\"\\n    }},\\n    \"type\": {{\\n        \"description\": \"Type of the document - possible value are article, lecture and patent\",\\n        \"type\": \"string\"\\n    }}\\n}}\\n}}\\n```\\n\\nUser Query:\\n{query}\\n\\nStructured Request:\\n', example_separator='\\n\\n', prefix='Your goal is to structure the user\\'s query to match the request schema provided below.\\n\\n<< Structured Request Schema >>\\nWhen responding use a markdown code snippet with a JSON object formatted in the following schema:\\n\\n```json\\n{{\\n    \"query\": string \\\\ text string to compare to document contents\\n    \"filter\": string \\\\ logical condition statement for filtering documents\\n}}\\n```\\n\\nThe query string should contain only text that is expected to match the contents of documents. Any conditions in the filter should not be mentioned in the query as well.\\n\\nA logical condition statement is composed of one or more comparison and logical operation statements.\\n\\nA comparison statement takes the form: `comp(attr, val)`:\\n- `comp` (eq | gt | gte | lt | lte): comparator\\n- `attr` (string):  name of attribute to apply the comparison to\\n- `val` (string): is the comparison value\\n\\nA logical operation statement takes the form `op(statement1, statement2, ...)`:\\n- `op` (and | or): logical operator\\n- `statement1`, `statement2`, ... (comparison statements or logical operation statements): one or more statements to apply the operation to\\n\\nMake sure that you only use the comparators and logical operators listed above and no others.\\nMake sure that filters only refer to attributes that exist in the data source.\\nMake sure that filters only use the attributed names with its function names if there are functions applied on them.\\nMake sure that filters only use format `YYYY-MM-DD` when handling timestamp data typed values.\\nMake sure that filters take into account the descriptions of attributes and only make comparisons that are feasible given the type of data being stored.\\nMake sure that filters are only used as needed. If there are no filters that should be applied return \"NO_FILTER\" for the filter value.', template_format='f-string'), llm=ChatOpenAI(cache=None, verbose=False, callbacks=None, callback_manager=None, tags=None, metadata=None, client=<class 'openai.api_resources.chat_completion.ChatCompletion'>, model_name='gpt-3.5-turbo', temperature=0.0, model_kwargs={}, openai_api_key='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', openai_api_base='', openai_organization='', openai_proxy='', request_timeout=None, max_retries=6, streaming=False, n=1, max_tokens=None, tiktoken_model_name=None), output_key='text', output_parser=StrOutputParser(), return_final_only=True, llm_kwargs={}), search_type='similarity', search_kwargs={}, structured_query_translator=<langchain.retrievers.self_query.chroma.ChromaTranslator object at 0x7fd69812a410>, verbose=True, use_original_query=False),\n",
       "  'ensemble_retriever': EnsembleRetriever(tags=None, metadata=None, retrievers=[VectorStoreRetriever(tags=['Chroma', 'OpenAIEmbeddings'], metadata=None, vectorstore=<langchain.vectorstores.chroma.Chroma object at 0x7fd6978c46d0>, search_type='mmr', search_kwargs={}), MultiQueryRetriever(tags=None, metadata=None, retriever=VectorStoreRetriever(tags=['Chroma', 'OpenAIEmbeddings'], metadata=None, vectorstore=<langchain.vectorstores.chroma.Chroma object at 0x7fd6978c46d0>, search_type='mmr', search_kwargs={}), llm_chain=LLMChain(memory=None, callbacks=None, callback_manager=None, verbose=False, tags=None, metadata=None, prompt=PromptTemplate(input_variables=['question'], output_parser=None, partial_variables={}, template='You are an AI language model assistant. Your task is \\n    to generate 3 different versions of the given user \\n    question to retrieve relevant documents from a vector  database. \\n    By generating multiple perspectives on the user question, \\n    your goal is to help the user overcome some of the limitations \\n    of distance-based similarity search. Provide these alternative \\n    questions separated by newlines. Original question: {question}', template_format='f-string', validate_template=True), llm=ChatOpenAI(cache=None, verbose=False, callbacks=None, callback_manager=None, tags=None, metadata=None, client=<class 'openai.api_resources.chat_completion.ChatCompletion'>, model_name='gpt-3.5-turbo', temperature=0.0, model_kwargs={}, openai_api_key='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', openai_api_base='', openai_organization='', openai_proxy='', request_timeout=None, max_retries=6, streaming=False, n=1, max_tokens=None, tiktoken_model_name=None), output_key='text', output_parser=LineListOutputParser(pydantic_object=<class 'langchain.retrievers.multi_query.LineList'>), return_final_only=True, llm_kwargs={}), verbose=True, parser_key='lines'), ContextualCompressionRetriever(tags=None, metadata=None, base_compressor=LLMChainExtractor(llm_chain=LLMChain(memory=None, callbacks=None, callback_manager=None, verbose=False, tags=None, metadata=None, prompt=PromptTemplate(input_variables=['question', 'context'], output_parser=NoOutputParser(no_output_str='NO_OUTPUT'), partial_variables={}, template='Given the following question and context, extract any part of the context *AS IS* that is relevant to answer the question. If none of the context is relevant return NO_OUTPUT. \\n\\nRemember, *DO NOT* edit the extracted parts of the context.\\n\\n> Question: {question}\\n> Context:\\n>>>\\n{context}\\n>>>\\nExtracted relevant parts:', template_format='f-string', validate_template=True), llm=ChatOpenAI(cache=None, verbose=False, callbacks=None, callback_manager=None, tags=None, metadata=None, client=<class 'openai.api_resources.chat_completion.ChatCompletion'>, model_name='gpt-3.5-turbo', temperature=0.0, model_kwargs={}, openai_api_key='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', openai_api_base='', openai_organization='', openai_proxy='', request_timeout=None, max_retries=6, streaming=False, n=1, max_tokens=None, tiktoken_model_name=None), output_key='text', output_parser=StrOutputParser(), return_final_only=True, llm_kwargs={}), get_input=<function default_get_input at 0x7fd6ed1bb910>), base_retriever=VectorStoreRetriever(tags=['Chroma', 'OpenAIEmbeddings'], metadata=None, vectorstore=<langchain.vectorstores.chroma.Chroma object at 0x7fd6978c46d0>, search_type='mmr', search_kwargs={})), SelfQueryRetriever(tags=None, metadata=None, vectorstore=<langchain.vectorstores.chroma.Chroma object at 0x7fd6978c46d0>, llm_chain=LLMChain(memory=None, callbacks=None, callback_manager=None, verbose=False, tags=None, metadata=None, prompt=FewShotPromptTemplate(input_variables=['query'], output_parser=StructuredQueryOutputParser(ast_parse=<bound method Lark.parse of Lark(open('<string>'), parser='lalr', lexer='contextual', ...)>), partial_variables={}, examples=[{'i': 1, 'data_source': '```json\\n{{\\n    \"content\": \"Lyrics of a song\",\\n    \"attributes\": {{\\n        \"artist\": {{\\n            \"type\": \"string\",\\n            \"description\": \"Name of the song artist\"\\n        }},\\n        \"length\": {{\\n            \"type\": \"integer\",\\n            \"description\": \"Length of the song in seconds\"\\n        }},\\n        \"genre\": {{\\n            \"type\": \"string\",\\n            \"description\": \"The song genre, one of \"pop\", \"rock\" or \"rap\"\"\\n        }}\\n    }}\\n}}\\n```', 'user_query': 'What are songs by Taylor Swift or Katy Perry about teenage romance under 3 minutes long in the dance pop genre', 'structured_request': '```json\\n{{\\n    \"query\": \"teenager love\",\\n    \"filter\": \"and(or(eq(\\\\\"artist\\\\\", \\\\\"Taylor Swift\\\\\"), eq(\\\\\"artist\\\\\", \\\\\"Katy Perry\\\\\")), lt(\\\\\"length\\\\\", 180), eq(\\\\\"genre\\\\\", \\\\\"pop\\\\\"))\"\\n}}\\n```'}, {'i': 2, 'data_source': '```json\\n{{\\n    \"content\": \"Lyrics of a song\",\\n    \"attributes\": {{\\n        \"artist\": {{\\n            \"type\": \"string\",\\n            \"description\": \"Name of the song artist\"\\n        }},\\n        \"length\": {{\\n            \"type\": \"integer\",\\n            \"description\": \"Length of the song in seconds\"\\n        }},\\n        \"genre\": {{\\n            \"type\": \"string\",\\n            \"description\": \"The song genre, one of \"pop\", \"rock\" or \"rap\"\"\\n        }}\\n    }}\\n}}\\n```', 'user_query': 'What are songs that were not published on Spotify', 'structured_request': '```json\\n{{\\n    \"query\": \"\",\\n    \"filter\": \"NO_FILTER\"\\n}}\\n```'}], example_selector=None, validate_template=True, example_prompt=PromptTemplate(input_variables=['i', 'data_source', 'user_query', 'structured_request'], output_parser=None, partial_variables={}, template='<< Example {i}. >>\\nData Source:\\n{data_source}\\n\\nUser Query:\\n{user_query}\\n\\nStructured Request:\\n{structured_request}\\n', template_format='f-string', validate_template=True), suffix='<< Example 3. >>\\nData Source:\\n```json\\n{{\\n    \"content\": \"Document content\",\\n    \"attributes\": {{\\n    \"category\": {{\\n        \"description\": \"Category of te text content - possible values are NarrativeText and Title\",\\n        \"type\": \"string\"\\n    }},\\n    \"date\": {{\\n        \"description\": \"Date when the document was published\",\\n        \"type\": \"string\"\\n    }},\\n    \"filename\": {{\\n        \"description\": \"Name of the file\",\\n        \"type\": \"string\"\\n    }},\\n    \"id\": {{\\n        \"description\": \"Document ID\",\\n        \"type\": \"string\"\\n    }},\\n    \"page_number\": {{\\n        \"description\": \"Page number from the original document\",\\n        \"type\": \"string\"\\n    }},\\n    \"register_num\": {{\\n        \"description\": \"Patent registration number\",\\n        \"type\": \"string\"\\n    }},\\n    \"source\": {{\\n        \"description\": \"Source that published the document\",\\n        \"type\": \"string\"\\n    }},\\n    \"title\": {{\\n        \"description\": \"Document title\",\\n        \"type\": \"string\"\\n    }},\\n    \"type\": {{\\n        \"description\": \"Type of the document - possible value are article, lecture and patent\",\\n        \"type\": \"string\"\\n    }}\\n}}\\n}}\\n```\\n\\nUser Query:\\n{query}\\n\\nStructured Request:\\n', example_separator='\\n\\n', prefix='Your goal is to structure the user\\'s query to match the request schema provided below.\\n\\n<< Structured Request Schema >>\\nWhen responding use a markdown code snippet with a JSON object formatted in the following schema:\\n\\n```json\\n{{\\n    \"query\": string \\\\ text string to compare to document contents\\n    \"filter\": string \\\\ logical condition statement for filtering documents\\n}}\\n```\\n\\nThe query string should contain only text that is expected to match the contents of documents. Any conditions in the filter should not be mentioned in the query as well.\\n\\nA logical condition statement is composed of one or more comparison and logical operation statements.\\n\\nA comparison statement takes the form: `comp(attr, val)`:\\n- `comp` (eq | gt | gte | lt | lte): comparator\\n- `attr` (string):  name of attribute to apply the comparison to\\n- `val` (string): is the comparison value\\n\\nA logical operation statement takes the form `op(statement1, statement2, ...)`:\\n- `op` (and | or): logical operator\\n- `statement1`, `statement2`, ... (comparison statements or logical operation statements): one or more statements to apply the operation to\\n\\nMake sure that you only use the comparators and logical operators listed above and no others.\\nMake sure that filters only refer to attributes that exist in the data source.\\nMake sure that filters only use the attributed names with its function names if there are functions applied on them.\\nMake sure that filters only use format `YYYY-MM-DD` when handling timestamp data typed values.\\nMake sure that filters take into account the descriptions of attributes and only make comparisons that are feasible given the type of data being stored.\\nMake sure that filters are only used as needed. If there are no filters that should be applied return \"NO_FILTER\" for the filter value.', template_format='f-string'), llm=ChatOpenAI(cache=None, verbose=False, callbacks=None, callback_manager=None, tags=None, metadata=None, client=<class 'openai.api_resources.chat_completion.ChatCompletion'>, model_name='gpt-3.5-turbo', temperature=0.0, model_kwargs={}, openai_api_key='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', openai_api_base='', openai_organization='', openai_proxy='', request_timeout=None, max_retries=6, streaming=False, n=1, max_tokens=None, tiktoken_model_name=None), output_key='text', output_parser=StrOutputParser(), return_final_only=True, llm_kwargs={}), search_type='similarity', search_kwargs={}, structured_query_translator=<langchain.retrievers.self_query.chroma.ChromaTranslator object at 0x7fd69812a410>, verbose=True, use_original_query=False), EnsembleRetriever(tags=None, metadata=None, retrievers=[VectorStoreRetriever(tags=['Chroma', 'OpenAIEmbeddings'], metadata=None, vectorstore=<langchain.vectorstores.chroma.Chroma object at 0x7fd6978c46d0>, search_type='mmr', search_kwargs={}), MultiQueryRetriever(tags=None, metadata=None, retriever=VectorStoreRetriever(tags=['Chroma', 'OpenAIEmbeddings'], metadata=None, vectorstore=<langchain.vectorstores.chroma.Chroma object at 0x7fd6978c46d0>, search_type='mmr', search_kwargs={}), llm_chain=LLMChain(memory=None, callbacks=None, callback_manager=None, verbose=False, tags=None, metadata=None, prompt=PromptTemplate(input_variables=['question'], output_parser=None, partial_variables={}, template='You are an AI language model assistant. Your task is \\n    to generate 3 different versions of the given user \\n    question to retrieve relevant documents from a vector  database. \\n    By generating multiple perspectives on the user question, \\n    your goal is to help the user overcome some of the limitations \\n    of distance-based similarity search. Provide these alternative \\n    questions separated by newlines. Original question: {question}', template_format='f-string', validate_template=True), llm=ChatOpenAI(cache=None, verbose=False, callbacks=None, callback_manager=None, tags=None, metadata=None, client=<class 'openai.api_resources.chat_completion.ChatCompletion'>, model_name='gpt-3.5-turbo', temperature=0.0, model_kwargs={}, openai_api_key='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', openai_api_base='', openai_organization='', openai_proxy='', request_timeout=None, max_retries=6, streaming=False, n=1, max_tokens=None, tiktoken_model_name=None), output_key='text', output_parser=LineListOutputParser(pydantic_object=<class 'langchain.retrievers.multi_query.LineList'>), return_final_only=True, llm_kwargs={}), verbose=True, parser_key='lines'), ContextualCompressionRetriever(tags=None, metadata=None, base_compressor=LLMChainExtractor(llm_chain=LLMChain(memory=None, callbacks=None, callback_manager=None, verbose=False, tags=None, metadata=None, prompt=PromptTemplate(input_variables=['question', 'context'], output_parser=NoOutputParser(no_output_str='NO_OUTPUT'), partial_variables={}, template='Given the following question and context, extract any part of the context *AS IS* that is relevant to answer the question. If none of the context is relevant return NO_OUTPUT. \\n\\nRemember, *DO NOT* edit the extracted parts of the context.\\n\\n> Question: {question}\\n> Context:\\n>>>\\n{context}\\n>>>\\nExtracted relevant parts:', template_format='f-string', validate_template=True), llm=ChatOpenAI(cache=None, verbose=False, callbacks=None, callback_manager=None, tags=None, metadata=None, client=<class 'openai.api_resources.chat_completion.ChatCompletion'>, model_name='gpt-3.5-turbo', temperature=0.0, model_kwargs={}, openai_api_key='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', openai_api_base='', openai_organization='', openai_proxy='', request_timeout=None, max_retries=6, streaming=False, n=1, max_tokens=None, tiktoken_model_name=None), output_key='text', output_parser=StrOutputParser(), return_final_only=True, llm_kwargs={}), get_input=<function default_get_input at 0x7fd6ed1bb910>), base_retriever=VectorStoreRetriever(tags=['Chroma', 'OpenAIEmbeddings'], metadata=None, vectorstore=<langchain.vectorstores.chroma.Chroma object at 0x7fd6978c46d0>, search_type='mmr', search_kwargs={})), SelfQueryRetriever(tags=None, metadata=None, vectorstore=<langchain.vectorstores.chroma.Chroma object at 0x7fd6978c46d0>, llm_chain=LLMChain(memory=None, callbacks=None, callback_manager=None, verbose=False, tags=None, metadata=None, prompt=FewShotPromptTemplate(input_variables=['query'], output_parser=StructuredQueryOutputParser(ast_parse=<bound method Lark.parse of Lark(open('<string>'), parser='lalr', lexer='contextual', ...)>), partial_variables={}, examples=[{'i': 1, 'data_source': '```json\\n{{\\n    \"content\": \"Lyrics of a song\",\\n    \"attributes\": {{\\n        \"artist\": {{\\n            \"type\": \"string\",\\n            \"description\": \"Name of the song artist\"\\n        }},\\n        \"length\": {{\\n            \"type\": \"integer\",\\n            \"description\": \"Length of the song in seconds\"\\n        }},\\n        \"genre\": {{\\n            \"type\": \"string\",\\n            \"description\": \"The song genre, one of \"pop\", \"rock\" or \"rap\"\"\\n        }}\\n    }}\\n}}\\n```', 'user_query': 'What are songs by Taylor Swift or Katy Perry about teenage romance under 3 minutes long in the dance pop genre', 'structured_request': '```json\\n{{\\n    \"query\": \"teenager love\",\\n    \"filter\": \"and(or(eq(\\\\\"artist\\\\\", \\\\\"Taylor Swift\\\\\"), eq(\\\\\"artist\\\\\", \\\\\"Katy Perry\\\\\")), lt(\\\\\"length\\\\\", 180), eq(\\\\\"genre\\\\\", \\\\\"pop\\\\\"))\"\\n}}\\n```'}, {'i': 2, 'data_source': '```json\\n{{\\n    \"content\": \"Lyrics of a song\",\\n    \"attributes\": {{\\n        \"artist\": {{\\n            \"type\": \"string\",\\n            \"description\": \"Name of the song artist\"\\n        }},\\n        \"length\": {{\\n            \"type\": \"integer\",\\n            \"description\": \"Length of the song in seconds\"\\n        }},\\n        \"genre\": {{\\n            \"type\": \"string\",\\n            \"description\": \"The song genre, one of \"pop\", \"rock\" or \"rap\"\"\\n        }}\\n    }}\\n}}\\n```', 'user_query': 'What are songs that were not published on Spotify', 'structured_request': '```json\\n{{\\n    \"query\": \"\",\\n    \"filter\": \"NO_FILTER\"\\n}}\\n```'}], example_selector=None, validate_template=True, example_prompt=PromptTemplate(input_variables=['i', 'data_source', 'user_query', 'structured_request'], output_parser=None, partial_variables={}, template='<< Example {i}. >>\\nData Source:\\n{data_source}\\n\\nUser Query:\\n{user_query}\\n\\nStructured Request:\\n{structured_request}\\n', template_format='f-string', validate_template=True), suffix='<< Example 3. >>\\nData Source:\\n```json\\n{{\\n    \"content\": \"Document content\",\\n    \"attributes\": {{\\n    \"category\": {{\\n        \"description\": \"Category of te text content - possible values are NarrativeText and Title\",\\n        \"type\": \"string\"\\n    }},\\n    \"date\": {{\\n        \"description\": \"Date when the document was published\",\\n        \"type\": \"string\"\\n    }},\\n    \"filename\": {{\\n        \"description\": \"Name of the file\",\\n        \"type\": \"string\"\\n    }},\\n    \"id\": {{\\n        \"description\": \"Document ID\",\\n        \"type\": \"string\"\\n    }},\\n    \"page_number\": {{\\n        \"description\": \"Page number from the original document\",\\n        \"type\": \"string\"\\n    }},\\n    \"register_num\": {{\\n        \"description\": \"Patent registration number\",\\n        \"type\": \"string\"\\n    }},\\n    \"source\": {{\\n        \"description\": \"Source that published the document\",\\n        \"type\": \"string\"\\n    }},\\n    \"title\": {{\\n        \"description\": \"Document title\",\\n        \"type\": \"string\"\\n    }},\\n    \"type\": {{\\n        \"description\": \"Type of the document - possible value are article, lecture and patent\",\\n        \"type\": \"string\"\\n    }}\\n}}\\n}}\\n```\\n\\nUser Query:\\n{query}\\n\\nStructured Request:\\n', example_separator='\\n\\n', prefix='Your goal is to structure the user\\'s query to match the request schema provided below.\\n\\n<< Structured Request Schema >>\\nWhen responding use a markdown code snippet with a JSON object formatted in the following schema:\\n\\n```json\\n{{\\n    \"query\": string \\\\ text string to compare to document contents\\n    \"filter\": string \\\\ logical condition statement for filtering documents\\n}}\\n```\\n\\nThe query string should contain only text that is expected to match the contents of documents. Any conditions in the filter should not be mentioned in the query as well.\\n\\nA logical condition statement is composed of one or more comparison and logical operation statements.\\n\\nA comparison statement takes the form: `comp(attr, val)`:\\n- `comp` (eq | gt | gte | lt | lte): comparator\\n- `attr` (string):  name of attribute to apply the comparison to\\n- `val` (string): is the comparison value\\n\\nA logical operation statement takes the form `op(statement1, statement2, ...)`:\\n- `op` (and | or): logical operator\\n- `statement1`, `statement2`, ... (comparison statements or logical operation statements): one or more statements to apply the operation to\\n\\nMake sure that you only use the comparators and logical operators listed above and no others.\\nMake sure that filters only refer to attributes that exist in the data source.\\nMake sure that filters only use the attributed names with its function names if there are functions applied on them.\\nMake sure that filters only use format `YYYY-MM-DD` when handling timestamp data typed values.\\nMake sure that filters take into account the descriptions of attributes and only make comparisons that are feasible given the type of data being stored.\\nMake sure that filters are only used as needed. If there are no filters that should be applied return \"NO_FILTER\" for the filter value.', template_format='f-string'), llm=ChatOpenAI(cache=None, verbose=False, callbacks=None, callback_manager=None, tags=None, metadata=None, client=<class 'openai.api_resources.chat_completion.ChatCompletion'>, model_name='gpt-3.5-turbo', temperature=0.0, model_kwargs={}, openai_api_key='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', openai_api_base='', openai_organization='', openai_proxy='', request_timeout=None, max_retries=6, streaming=False, n=1, max_tokens=None, tiktoken_model_name=None), output_key='text', output_parser=StrOutputParser(), return_final_only=True, llm_kwargs={}), search_type='similarity', search_kwargs={}, structured_query_translator=<langchain.retrievers.self_query.chroma.ChromaTranslator object at 0x7fd696a9abc0>, verbose=True, use_original_query=False)], weights=[0.25, 0.25, 0.25, 0.25], c=60)], weights=[0.2, 0.2, 0.2, 0.2, 0.2], c=60)},\n",
       " 'nltk': {'base': VectorStoreRetriever(tags=['Chroma', 'OpenAIEmbeddings'], metadata=None, vectorstore=<langchain.vectorstores.chroma.Chroma object at 0x7fd6978c4b80>, search_type='mmr', search_kwargs={}),\n",
       "  'multi_query': MultiQueryRetriever(tags=None, metadata=None, retriever=VectorStoreRetriever(tags=['Chroma', 'OpenAIEmbeddings'], metadata=None, vectorstore=<langchain.vectorstores.chroma.Chroma object at 0x7fd6978c4b80>, search_type='mmr', search_kwargs={}), llm_chain=LLMChain(memory=None, callbacks=None, callback_manager=None, verbose=False, tags=None, metadata=None, prompt=PromptTemplate(input_variables=['question'], output_parser=None, partial_variables={}, template='You are an AI language model assistant. Your task is \\n    to generate 3 different versions of the given user \\n    question to retrieve relevant documents from a vector  database. \\n    By generating multiple perspectives on the user question, \\n    your goal is to help the user overcome some of the limitations \\n    of distance-based similarity search. Provide these alternative \\n    questions separated by newlines. Original question: {question}', template_format='f-string', validate_template=True), llm=ChatOpenAI(cache=None, verbose=False, callbacks=None, callback_manager=None, tags=None, metadata=None, client=<class 'openai.api_resources.chat_completion.ChatCompletion'>, model_name='gpt-3.5-turbo', temperature=0.0, model_kwargs={}, openai_api_key='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', openai_api_base='', openai_organization='', openai_proxy='', request_timeout=None, max_retries=6, streaming=False, n=1, max_tokens=None, tiktoken_model_name=None), output_key='text', output_parser=LineListOutputParser(pydantic_object=<class 'langchain.retrievers.multi_query.LineList'>), return_final_only=True, llm_kwargs={}), verbose=True, parser_key='lines'),\n",
       "  'compression_retriever': ContextualCompressionRetriever(tags=None, metadata=None, base_compressor=LLMChainExtractor(llm_chain=LLMChain(memory=None, callbacks=None, callback_manager=None, verbose=False, tags=None, metadata=None, prompt=PromptTemplate(input_variables=['question', 'context'], output_parser=NoOutputParser(no_output_str='NO_OUTPUT'), partial_variables={}, template='Given the following question and context, extract any part of the context *AS IS* that is relevant to answer the question. If none of the context is relevant return NO_OUTPUT. \\n\\nRemember, *DO NOT* edit the extracted parts of the context.\\n\\n> Question: {question}\\n> Context:\\n>>>\\n{context}\\n>>>\\nExtracted relevant parts:', template_format='f-string', validate_template=True), llm=ChatOpenAI(cache=None, verbose=False, callbacks=None, callback_manager=None, tags=None, metadata=None, client=<class 'openai.api_resources.chat_completion.ChatCompletion'>, model_name='gpt-3.5-turbo', temperature=0.0, model_kwargs={}, openai_api_key='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', openai_api_base='', openai_organization='', openai_proxy='', request_timeout=None, max_retries=6, streaming=False, n=1, max_tokens=None, tiktoken_model_name=None), output_key='text', output_parser=StrOutputParser(), return_final_only=True, llm_kwargs={}), get_input=<function default_get_input at 0x7fd6ed1bb910>), base_retriever=VectorStoreRetriever(tags=['Chroma', 'OpenAIEmbeddings'], metadata=None, vectorstore=<langchain.vectorstores.chroma.Chroma object at 0x7fd6978c4b80>, search_type='mmr', search_kwargs={})),\n",
       "  'self_query_retriever': SelfQueryRetriever(tags=None, metadata=None, vectorstore=<langchain.vectorstores.chroma.Chroma object at 0x7fd6978c4b80>, llm_chain=LLMChain(memory=None, callbacks=None, callback_manager=None, verbose=False, tags=None, metadata=None, prompt=FewShotPromptTemplate(input_variables=['query'], output_parser=StructuredQueryOutputParser(ast_parse=<bound method Lark.parse of Lark(open('<string>'), parser='lalr', lexer='contextual', ...)>), partial_variables={}, examples=[{'i': 1, 'data_source': '```json\\n{{\\n    \"content\": \"Lyrics of a song\",\\n    \"attributes\": {{\\n        \"artist\": {{\\n            \"type\": \"string\",\\n            \"description\": \"Name of the song artist\"\\n        }},\\n        \"length\": {{\\n            \"type\": \"integer\",\\n            \"description\": \"Length of the song in seconds\"\\n        }},\\n        \"genre\": {{\\n            \"type\": \"string\",\\n            \"description\": \"The song genre, one of \"pop\", \"rock\" or \"rap\"\"\\n        }}\\n    }}\\n}}\\n```', 'user_query': 'What are songs by Taylor Swift or Katy Perry about teenage romance under 3 minutes long in the dance pop genre', 'structured_request': '```json\\n{{\\n    \"query\": \"teenager love\",\\n    \"filter\": \"and(or(eq(\\\\\"artist\\\\\", \\\\\"Taylor Swift\\\\\"), eq(\\\\\"artist\\\\\", \\\\\"Katy Perry\\\\\")), lt(\\\\\"length\\\\\", 180), eq(\\\\\"genre\\\\\", \\\\\"pop\\\\\"))\"\\n}}\\n```'}, {'i': 2, 'data_source': '```json\\n{{\\n    \"content\": \"Lyrics of a song\",\\n    \"attributes\": {{\\n        \"artist\": {{\\n            \"type\": \"string\",\\n            \"description\": \"Name of the song artist\"\\n        }},\\n        \"length\": {{\\n            \"type\": \"integer\",\\n            \"description\": \"Length of the song in seconds\"\\n        }},\\n        \"genre\": {{\\n            \"type\": \"string\",\\n            \"description\": \"The song genre, one of \"pop\", \"rock\" or \"rap\"\"\\n        }}\\n    }}\\n}}\\n```', 'user_query': 'What are songs that were not published on Spotify', 'structured_request': '```json\\n{{\\n    \"query\": \"\",\\n    \"filter\": \"NO_FILTER\"\\n}}\\n```'}], example_selector=None, validate_template=True, example_prompt=PromptTemplate(input_variables=['i', 'data_source', 'user_query', 'structured_request'], output_parser=None, partial_variables={}, template='<< Example {i}. >>\\nData Source:\\n{data_source}\\n\\nUser Query:\\n{user_query}\\n\\nStructured Request:\\n{structured_request}\\n', template_format='f-string', validate_template=True), suffix='<< Example 3. >>\\nData Source:\\n```json\\n{{\\n    \"content\": \"Document content\",\\n    \"attributes\": {{\\n    \"category\": {{\\n        \"description\": \"Category of te text content - possible values are NarrativeText and Title\",\\n        \"type\": \"string\"\\n    }},\\n    \"date\": {{\\n        \"description\": \"Date when the document was published\",\\n        \"type\": \"string\"\\n    }},\\n    \"filename\": {{\\n        \"description\": \"Name of the file\",\\n        \"type\": \"string\"\\n    }},\\n    \"id\": {{\\n        \"description\": \"Document ID\",\\n        \"type\": \"string\"\\n    }},\\n    \"page_number\": {{\\n        \"description\": \"Page number from the original document\",\\n        \"type\": \"string\"\\n    }},\\n    \"register_num\": {{\\n        \"description\": \"Patent registration number\",\\n        \"type\": \"string\"\\n    }},\\n    \"source\": {{\\n        \"description\": \"Source that published the document\",\\n        \"type\": \"string\"\\n    }},\\n    \"title\": {{\\n        \"description\": \"Document title\",\\n        \"type\": \"string\"\\n    }},\\n    \"type\": {{\\n        \"description\": \"Type of the document - possible value are article, lecture and patent\",\\n        \"type\": \"string\"\\n    }}\\n}}\\n}}\\n```\\n\\nUser Query:\\n{query}\\n\\nStructured Request:\\n', example_separator='\\n\\n', prefix='Your goal is to structure the user\\'s query to match the request schema provided below.\\n\\n<< Structured Request Schema >>\\nWhen responding use a markdown code snippet with a JSON object formatted in the following schema:\\n\\n```json\\n{{\\n    \"query\": string \\\\ text string to compare to document contents\\n    \"filter\": string \\\\ logical condition statement for filtering documents\\n}}\\n```\\n\\nThe query string should contain only text that is expected to match the contents of documents. Any conditions in the filter should not be mentioned in the query as well.\\n\\nA logical condition statement is composed of one or more comparison and logical operation statements.\\n\\nA comparison statement takes the form: `comp(attr, val)`:\\n- `comp` (eq | gt | gte | lt | lte): comparator\\n- `attr` (string):  name of attribute to apply the comparison to\\n- `val` (string): is the comparison value\\n\\nA logical operation statement takes the form `op(statement1, statement2, ...)`:\\n- `op` (and | or): logical operator\\n- `statement1`, `statement2`, ... (comparison statements or logical operation statements): one or more statements to apply the operation to\\n\\nMake sure that you only use the comparators and logical operators listed above and no others.\\nMake sure that filters only refer to attributes that exist in the data source.\\nMake sure that filters only use the attributed names with its function names if there are functions applied on them.\\nMake sure that filters only use format `YYYY-MM-DD` when handling timestamp data typed values.\\nMake sure that filters take into account the descriptions of attributes and only make comparisons that are feasible given the type of data being stored.\\nMake sure that filters are only used as needed. If there are no filters that should be applied return \"NO_FILTER\" for the filter value.', template_format='f-string'), llm=ChatOpenAI(cache=None, verbose=False, callbacks=None, callback_manager=None, tags=None, metadata=None, client=<class 'openai.api_resources.chat_completion.ChatCompletion'>, model_name='gpt-3.5-turbo', temperature=0.0, model_kwargs={}, openai_api_key='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', openai_api_base='', openai_organization='', openai_proxy='', request_timeout=None, max_retries=6, streaming=False, n=1, max_tokens=None, tiktoken_model_name=None), output_key='text', output_parser=StrOutputParser(), return_final_only=True, llm_kwargs={}), search_type='similarity', search_kwargs={}, structured_query_translator=<langchain.retrievers.self_query.chroma.ChromaTranslator object at 0x7fd698129db0>, verbose=True, use_original_query=False),\n",
       "  'ensemble_retriever': EnsembleRetriever(tags=None, metadata=None, retrievers=[VectorStoreRetriever(tags=['Chroma', 'OpenAIEmbeddings'], metadata=None, vectorstore=<langchain.vectorstores.chroma.Chroma object at 0x7fd6978c4b80>, search_type='mmr', search_kwargs={}), MultiQueryRetriever(tags=None, metadata=None, retriever=VectorStoreRetriever(tags=['Chroma', 'OpenAIEmbeddings'], metadata=None, vectorstore=<langchain.vectorstores.chroma.Chroma object at 0x7fd6978c4b80>, search_type='mmr', search_kwargs={}), llm_chain=LLMChain(memory=None, callbacks=None, callback_manager=None, verbose=False, tags=None, metadata=None, prompt=PromptTemplate(input_variables=['question'], output_parser=None, partial_variables={}, template='You are an AI language model assistant. Your task is \\n    to generate 3 different versions of the given user \\n    question to retrieve relevant documents from a vector  database. \\n    By generating multiple perspectives on the user question, \\n    your goal is to help the user overcome some of the limitations \\n    of distance-based similarity search. Provide these alternative \\n    questions separated by newlines. Original question: {question}', template_format='f-string', validate_template=True), llm=ChatOpenAI(cache=None, verbose=False, callbacks=None, callback_manager=None, tags=None, metadata=None, client=<class 'openai.api_resources.chat_completion.ChatCompletion'>, model_name='gpt-3.5-turbo', temperature=0.0, model_kwargs={}, openai_api_key='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', openai_api_base='', openai_organization='', openai_proxy='', request_timeout=None, max_retries=6, streaming=False, n=1, max_tokens=None, tiktoken_model_name=None), output_key='text', output_parser=LineListOutputParser(pydantic_object=<class 'langchain.retrievers.multi_query.LineList'>), return_final_only=True, llm_kwargs={}), verbose=True, parser_key='lines'), ContextualCompressionRetriever(tags=None, metadata=None, base_compressor=LLMChainExtractor(llm_chain=LLMChain(memory=None, callbacks=None, callback_manager=None, verbose=False, tags=None, metadata=None, prompt=PromptTemplate(input_variables=['question', 'context'], output_parser=NoOutputParser(no_output_str='NO_OUTPUT'), partial_variables={}, template='Given the following question and context, extract any part of the context *AS IS* that is relevant to answer the question. If none of the context is relevant return NO_OUTPUT. \\n\\nRemember, *DO NOT* edit the extracted parts of the context.\\n\\n> Question: {question}\\n> Context:\\n>>>\\n{context}\\n>>>\\nExtracted relevant parts:', template_format='f-string', validate_template=True), llm=ChatOpenAI(cache=None, verbose=False, callbacks=None, callback_manager=None, tags=None, metadata=None, client=<class 'openai.api_resources.chat_completion.ChatCompletion'>, model_name='gpt-3.5-turbo', temperature=0.0, model_kwargs={}, openai_api_key='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', openai_api_base='', openai_organization='', openai_proxy='', request_timeout=None, max_retries=6, streaming=False, n=1, max_tokens=None, tiktoken_model_name=None), output_key='text', output_parser=StrOutputParser(), return_final_only=True, llm_kwargs={}), get_input=<function default_get_input at 0x7fd6ed1bb910>), base_retriever=VectorStoreRetriever(tags=['Chroma', 'OpenAIEmbeddings'], metadata=None, vectorstore=<langchain.vectorstores.chroma.Chroma object at 0x7fd6978c4b80>, search_type='mmr', search_kwargs={})), SelfQueryRetriever(tags=None, metadata=None, vectorstore=<langchain.vectorstores.chroma.Chroma object at 0x7fd6978c4b80>, llm_chain=LLMChain(memory=None, callbacks=None, callback_manager=None, verbose=False, tags=None, metadata=None, prompt=FewShotPromptTemplate(input_variables=['query'], output_parser=StructuredQueryOutputParser(ast_parse=<bound method Lark.parse of Lark(open('<string>'), parser='lalr', lexer='contextual', ...)>), partial_variables={}, examples=[{'i': 1, 'data_source': '```json\\n{{\\n    \"content\": \"Lyrics of a song\",\\n    \"attributes\": {{\\n        \"artist\": {{\\n            \"type\": \"string\",\\n            \"description\": \"Name of the song artist\"\\n        }},\\n        \"length\": {{\\n            \"type\": \"integer\",\\n            \"description\": \"Length of the song in seconds\"\\n        }},\\n        \"genre\": {{\\n            \"type\": \"string\",\\n            \"description\": \"The song genre, one of \"pop\", \"rock\" or \"rap\"\"\\n        }}\\n    }}\\n}}\\n```', 'user_query': 'What are songs by Taylor Swift or Katy Perry about teenage romance under 3 minutes long in the dance pop genre', 'structured_request': '```json\\n{{\\n    \"query\": \"teenager love\",\\n    \"filter\": \"and(or(eq(\\\\\"artist\\\\\", \\\\\"Taylor Swift\\\\\"), eq(\\\\\"artist\\\\\", \\\\\"Katy Perry\\\\\")), lt(\\\\\"length\\\\\", 180), eq(\\\\\"genre\\\\\", \\\\\"pop\\\\\"))\"\\n}}\\n```'}, {'i': 2, 'data_source': '```json\\n{{\\n    \"content\": \"Lyrics of a song\",\\n    \"attributes\": {{\\n        \"artist\": {{\\n            \"type\": \"string\",\\n            \"description\": \"Name of the song artist\"\\n        }},\\n        \"length\": {{\\n            \"type\": \"integer\",\\n            \"description\": \"Length of the song in seconds\"\\n        }},\\n        \"genre\": {{\\n            \"type\": \"string\",\\n            \"description\": \"The song genre, one of \"pop\", \"rock\" or \"rap\"\"\\n        }}\\n    }}\\n}}\\n```', 'user_query': 'What are songs that were not published on Spotify', 'structured_request': '```json\\n{{\\n    \"query\": \"\",\\n    \"filter\": \"NO_FILTER\"\\n}}\\n```'}], example_selector=None, validate_template=True, example_prompt=PromptTemplate(input_variables=['i', 'data_source', 'user_query', 'structured_request'], output_parser=None, partial_variables={}, template='<< Example {i}. >>\\nData Source:\\n{data_source}\\n\\nUser Query:\\n{user_query}\\n\\nStructured Request:\\n{structured_request}\\n', template_format='f-string', validate_template=True), suffix='<< Example 3. >>\\nData Source:\\n```json\\n{{\\n    \"content\": \"Document content\",\\n    \"attributes\": {{\\n    \"category\": {{\\n        \"description\": \"Category of te text content - possible values are NarrativeText and Title\",\\n        \"type\": \"string\"\\n    }},\\n    \"date\": {{\\n        \"description\": \"Date when the document was published\",\\n        \"type\": \"string\"\\n    }},\\n    \"filename\": {{\\n        \"description\": \"Name of the file\",\\n        \"type\": \"string\"\\n    }},\\n    \"id\": {{\\n        \"description\": \"Document ID\",\\n        \"type\": \"string\"\\n    }},\\n    \"page_number\": {{\\n        \"description\": \"Page number from the original document\",\\n        \"type\": \"string\"\\n    }},\\n    \"register_num\": {{\\n        \"description\": \"Patent registration number\",\\n        \"type\": \"string\"\\n    }},\\n    \"source\": {{\\n        \"description\": \"Source that published the document\",\\n        \"type\": \"string\"\\n    }},\\n    \"title\": {{\\n        \"description\": \"Document title\",\\n        \"type\": \"string\"\\n    }},\\n    \"type\": {{\\n        \"description\": \"Type of the document - possible value are article, lecture and patent\",\\n        \"type\": \"string\"\\n    }}\\n}}\\n}}\\n```\\n\\nUser Query:\\n{query}\\n\\nStructured Request:\\n', example_separator='\\n\\n', prefix='Your goal is to structure the user\\'s query to match the request schema provided below.\\n\\n<< Structured Request Schema >>\\nWhen responding use a markdown code snippet with a JSON object formatted in the following schema:\\n\\n```json\\n{{\\n    \"query\": string \\\\ text string to compare to document contents\\n    \"filter\": string \\\\ logical condition statement for filtering documents\\n}}\\n```\\n\\nThe query string should contain only text that is expected to match the contents of documents. Any conditions in the filter should not be mentioned in the query as well.\\n\\nA logical condition statement is composed of one or more comparison and logical operation statements.\\n\\nA comparison statement takes the form: `comp(attr, val)`:\\n- `comp` (eq | gt | gte | lt | lte): comparator\\n- `attr` (string):  name of attribute to apply the comparison to\\n- `val` (string): is the comparison value\\n\\nA logical operation statement takes the form `op(statement1, statement2, ...)`:\\n- `op` (and | or): logical operator\\n- `statement1`, `statement2`, ... (comparison statements or logical operation statements): one or more statements to apply the operation to\\n\\nMake sure that you only use the comparators and logical operators listed above and no others.\\nMake sure that filters only refer to attributes that exist in the data source.\\nMake sure that filters only use the attributed names with its function names if there are functions applied on them.\\nMake sure that filters only use format `YYYY-MM-DD` when handling timestamp data typed values.\\nMake sure that filters take into account the descriptions of attributes and only make comparisons that are feasible given the type of data being stored.\\nMake sure that filters are only used as needed. If there are no filters that should be applied return \"NO_FILTER\" for the filter value.', template_format='f-string'), llm=ChatOpenAI(cache=None, verbose=False, callbacks=None, callback_manager=None, tags=None, metadata=None, client=<class 'openai.api_resources.chat_completion.ChatCompletion'>, model_name='gpt-3.5-turbo', temperature=0.0, model_kwargs={}, openai_api_key='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', openai_api_base='', openai_organization='', openai_proxy='', request_timeout=None, max_retries=6, streaming=False, n=1, max_tokens=None, tiktoken_model_name=None), output_key='text', output_parser=StrOutputParser(), return_final_only=True, llm_kwargs={}), search_type='similarity', search_kwargs={}, structured_query_translator=<langchain.retrievers.self_query.chroma.ChromaTranslator object at 0x7fd698129db0>, verbose=True, use_original_query=False), EnsembleRetriever(tags=None, metadata=None, retrievers=[VectorStoreRetriever(tags=['Chroma', 'OpenAIEmbeddings'], metadata=None, vectorstore=<langchain.vectorstores.chroma.Chroma object at 0x7fd6978c4b80>, search_type='mmr', search_kwargs={}), MultiQueryRetriever(tags=None, metadata=None, retriever=VectorStoreRetriever(tags=['Chroma', 'OpenAIEmbeddings'], metadata=None, vectorstore=<langchain.vectorstores.chroma.Chroma object at 0x7fd6978c4b80>, search_type='mmr', search_kwargs={}), llm_chain=LLMChain(memory=None, callbacks=None, callback_manager=None, verbose=False, tags=None, metadata=None, prompt=PromptTemplate(input_variables=['question'], output_parser=None, partial_variables={}, template='You are an AI language model assistant. Your task is \\n    to generate 3 different versions of the given user \\n    question to retrieve relevant documents from a vector  database. \\n    By generating multiple perspectives on the user question, \\n    your goal is to help the user overcome some of the limitations \\n    of distance-based similarity search. Provide these alternative \\n    questions separated by newlines. Original question: {question}', template_format='f-string', validate_template=True), llm=ChatOpenAI(cache=None, verbose=False, callbacks=None, callback_manager=None, tags=None, metadata=None, client=<class 'openai.api_resources.chat_completion.ChatCompletion'>, model_name='gpt-3.5-turbo', temperature=0.0, model_kwargs={}, openai_api_key='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', openai_api_base='', openai_organization='', openai_proxy='', request_timeout=None, max_retries=6, streaming=False, n=1, max_tokens=None, tiktoken_model_name=None), output_key='text', output_parser=LineListOutputParser(pydantic_object=<class 'langchain.retrievers.multi_query.LineList'>), return_final_only=True, llm_kwargs={}), verbose=True, parser_key='lines'), ContextualCompressionRetriever(tags=None, metadata=None, base_compressor=LLMChainExtractor(llm_chain=LLMChain(memory=None, callbacks=None, callback_manager=None, verbose=False, tags=None, metadata=None, prompt=PromptTemplate(input_variables=['question', 'context'], output_parser=NoOutputParser(no_output_str='NO_OUTPUT'), partial_variables={}, template='Given the following question and context, extract any part of the context *AS IS* that is relevant to answer the question. If none of the context is relevant return NO_OUTPUT. \\n\\nRemember, *DO NOT* edit the extracted parts of the context.\\n\\n> Question: {question}\\n> Context:\\n>>>\\n{context}\\n>>>\\nExtracted relevant parts:', template_format='f-string', validate_template=True), llm=ChatOpenAI(cache=None, verbose=False, callbacks=None, callback_manager=None, tags=None, metadata=None, client=<class 'openai.api_resources.chat_completion.ChatCompletion'>, model_name='gpt-3.5-turbo', temperature=0.0, model_kwargs={}, openai_api_key='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', openai_api_base='', openai_organization='', openai_proxy='', request_timeout=None, max_retries=6, streaming=False, n=1, max_tokens=None, tiktoken_model_name=None), output_key='text', output_parser=StrOutputParser(), return_final_only=True, llm_kwargs={}), get_input=<function default_get_input at 0x7fd6ed1bb910>), base_retriever=VectorStoreRetriever(tags=['Chroma', 'OpenAIEmbeddings'], metadata=None, vectorstore=<langchain.vectorstores.chroma.Chroma object at 0x7fd6978c4b80>, search_type='mmr', search_kwargs={})), SelfQueryRetriever(tags=None, metadata=None, vectorstore=<langchain.vectorstores.chroma.Chroma object at 0x7fd6978c4b80>, llm_chain=LLMChain(memory=None, callbacks=None, callback_manager=None, verbose=False, tags=None, metadata=None, prompt=FewShotPromptTemplate(input_variables=['query'], output_parser=StructuredQueryOutputParser(ast_parse=<bound method Lark.parse of Lark(open('<string>'), parser='lalr', lexer='contextual', ...)>), partial_variables={}, examples=[{'i': 1, 'data_source': '```json\\n{{\\n    \"content\": \"Lyrics of a song\",\\n    \"attributes\": {{\\n        \"artist\": {{\\n            \"type\": \"string\",\\n            \"description\": \"Name of the song artist\"\\n        }},\\n        \"length\": {{\\n            \"type\": \"integer\",\\n            \"description\": \"Length of the song in seconds\"\\n        }},\\n        \"genre\": {{\\n            \"type\": \"string\",\\n            \"description\": \"The song genre, one of \"pop\", \"rock\" or \"rap\"\"\\n        }}\\n    }}\\n}}\\n```', 'user_query': 'What are songs by Taylor Swift or Katy Perry about teenage romance under 3 minutes long in the dance pop genre', 'structured_request': '```json\\n{{\\n    \"query\": \"teenager love\",\\n    \"filter\": \"and(or(eq(\\\\\"artist\\\\\", \\\\\"Taylor Swift\\\\\"), eq(\\\\\"artist\\\\\", \\\\\"Katy Perry\\\\\")), lt(\\\\\"length\\\\\", 180), eq(\\\\\"genre\\\\\", \\\\\"pop\\\\\"))\"\\n}}\\n```'}, {'i': 2, 'data_source': '```json\\n{{\\n    \"content\": \"Lyrics of a song\",\\n    \"attributes\": {{\\n        \"artist\": {{\\n            \"type\": \"string\",\\n            \"description\": \"Name of the song artist\"\\n        }},\\n        \"length\": {{\\n            \"type\": \"integer\",\\n            \"description\": \"Length of the song in seconds\"\\n        }},\\n        \"genre\": {{\\n            \"type\": \"string\",\\n            \"description\": \"The song genre, one of \"pop\", \"rock\" or \"rap\"\"\\n        }}\\n    }}\\n}}\\n```', 'user_query': 'What are songs that were not published on Spotify', 'structured_request': '```json\\n{{\\n    \"query\": \"\",\\n    \"filter\": \"NO_FILTER\"\\n}}\\n```'}], example_selector=None, validate_template=True, example_prompt=PromptTemplate(input_variables=['i', 'data_source', 'user_query', 'structured_request'], output_parser=None, partial_variables={}, template='<< Example {i}. >>\\nData Source:\\n{data_source}\\n\\nUser Query:\\n{user_query}\\n\\nStructured Request:\\n{structured_request}\\n', template_format='f-string', validate_template=True), suffix='<< Example 3. >>\\nData Source:\\n```json\\n{{\\n    \"content\": \"Document content\",\\n    \"attributes\": {{\\n    \"category\": {{\\n        \"description\": \"Category of te text content - possible values are NarrativeText and Title\",\\n        \"type\": \"string\"\\n    }},\\n    \"date\": {{\\n        \"description\": \"Date when the document was published\",\\n        \"type\": \"string\"\\n    }},\\n    \"filename\": {{\\n        \"description\": \"Name of the file\",\\n        \"type\": \"string\"\\n    }},\\n    \"id\": {{\\n        \"description\": \"Document ID\",\\n        \"type\": \"string\"\\n    }},\\n    \"page_number\": {{\\n        \"description\": \"Page number from the original document\",\\n        \"type\": \"string\"\\n    }},\\n    \"register_num\": {{\\n        \"description\": \"Patent registration number\",\\n        \"type\": \"string\"\\n    }},\\n    \"source\": {{\\n        \"description\": \"Source that published the document\",\\n        \"type\": \"string\"\\n    }},\\n    \"title\": {{\\n        \"description\": \"Document title\",\\n        \"type\": \"string\"\\n    }},\\n    \"type\": {{\\n        \"description\": \"Type of the document - possible value are article, lecture and patent\",\\n        \"type\": \"string\"\\n    }}\\n}}\\n}}\\n```\\n\\nUser Query:\\n{query}\\n\\nStructured Request:\\n', example_separator='\\n\\n', prefix='Your goal is to structure the user\\'s query to match the request schema provided below.\\n\\n<< Structured Request Schema >>\\nWhen responding use a markdown code snippet with a JSON object formatted in the following schema:\\n\\n```json\\n{{\\n    \"query\": string \\\\ text string to compare to document contents\\n    \"filter\": string \\\\ logical condition statement for filtering documents\\n}}\\n```\\n\\nThe query string should contain only text that is expected to match the contents of documents. Any conditions in the filter should not be mentioned in the query as well.\\n\\nA logical condition statement is composed of one or more comparison and logical operation statements.\\n\\nA comparison statement takes the form: `comp(attr, val)`:\\n- `comp` (eq | gt | gte | lt | lte): comparator\\n- `attr` (string):  name of attribute to apply the comparison to\\n- `val` (string): is the comparison value\\n\\nA logical operation statement takes the form `op(statement1, statement2, ...)`:\\n- `op` (and | or): logical operator\\n- `statement1`, `statement2`, ... (comparison statements or logical operation statements): one or more statements to apply the operation to\\n\\nMake sure that you only use the comparators and logical operators listed above and no others.\\nMake sure that filters only refer to attributes that exist in the data source.\\nMake sure that filters only use the attributed names with its function names if there are functions applied on them.\\nMake sure that filters only use format `YYYY-MM-DD` when handling timestamp data typed values.\\nMake sure that filters take into account the descriptions of attributes and only make comparisons that are feasible given the type of data being stored.\\nMake sure that filters are only used as needed. If there are no filters that should be applied return \"NO_FILTER\" for the filter value.', template_format='f-string'), llm=ChatOpenAI(cache=None, verbose=False, callbacks=None, callback_manager=None, tags=None, metadata=None, client=<class 'openai.api_resources.chat_completion.ChatCompletion'>, model_name='gpt-3.5-turbo', temperature=0.0, model_kwargs={}, openai_api_key='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', openai_api_base='', openai_organization='', openai_proxy='', request_timeout=None, max_retries=6, streaming=False, n=1, max_tokens=None, tiktoken_model_name=None), output_key='text', output_parser=StrOutputParser(), return_final_only=True, llm_kwargs={}), search_type='similarity', search_kwargs={}, structured_query_translator=<langchain.retrievers.self_query.chroma.ChromaTranslator object at 0x7fd696a9ac20>, verbose=True, use_original_query=False)], weights=[0.25, 0.25, 0.25, 0.25], c=60)], weights=[0.2, 0.2, 0.2, 0.2, 0.2], c=60)},\n",
       " 'recursive': {'base': VectorStoreRetriever(tags=['Chroma', 'OpenAIEmbeddings'], metadata=None, vectorstore=<langchain.vectorstores.chroma.Chroma object at 0x7fd6ed1b3f40>, search_type='mmr', search_kwargs={}),\n",
       "  'multi_query': MultiQueryRetriever(tags=None, metadata=None, retriever=VectorStoreRetriever(tags=['Chroma', 'OpenAIEmbeddings'], metadata=None, vectorstore=<langchain.vectorstores.chroma.Chroma object at 0x7fd6ed1b3f40>, search_type='mmr', search_kwargs={}), llm_chain=LLMChain(memory=None, callbacks=None, callback_manager=None, verbose=False, tags=None, metadata=None, prompt=PromptTemplate(input_variables=['question'], output_parser=None, partial_variables={}, template='You are an AI language model assistant. Your task is \\n    to generate 3 different versions of the given user \\n    question to retrieve relevant documents from a vector  database. \\n    By generating multiple perspectives on the user question, \\n    your goal is to help the user overcome some of the limitations \\n    of distance-based similarity search. Provide these alternative \\n    questions separated by newlines. Original question: {question}', template_format='f-string', validate_template=True), llm=ChatOpenAI(cache=None, verbose=False, callbacks=None, callback_manager=None, tags=None, metadata=None, client=<class 'openai.api_resources.chat_completion.ChatCompletion'>, model_name='gpt-3.5-turbo', temperature=0.0, model_kwargs={}, openai_api_key='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', openai_api_base='', openai_organization='', openai_proxy='', request_timeout=None, max_retries=6, streaming=False, n=1, max_tokens=None, tiktoken_model_name=None), output_key='text', output_parser=LineListOutputParser(pydantic_object=<class 'langchain.retrievers.multi_query.LineList'>), return_final_only=True, llm_kwargs={}), verbose=True, parser_key='lines'),\n",
       "  'compression_retriever': ContextualCompressionRetriever(tags=None, metadata=None, base_compressor=LLMChainExtractor(llm_chain=LLMChain(memory=None, callbacks=None, callback_manager=None, verbose=False, tags=None, metadata=None, prompt=PromptTemplate(input_variables=['question', 'context'], output_parser=NoOutputParser(no_output_str='NO_OUTPUT'), partial_variables={}, template='Given the following question and context, extract any part of the context *AS IS* that is relevant to answer the question. If none of the context is relevant return NO_OUTPUT. \\n\\nRemember, *DO NOT* edit the extracted parts of the context.\\n\\n> Question: {question}\\n> Context:\\n>>>\\n{context}\\n>>>\\nExtracted relevant parts:', template_format='f-string', validate_template=True), llm=ChatOpenAI(cache=None, verbose=False, callbacks=None, callback_manager=None, tags=None, metadata=None, client=<class 'openai.api_resources.chat_completion.ChatCompletion'>, model_name='gpt-3.5-turbo', temperature=0.0, model_kwargs={}, openai_api_key='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', openai_api_base='', openai_organization='', openai_proxy='', request_timeout=None, max_retries=6, streaming=False, n=1, max_tokens=None, tiktoken_model_name=None), output_key='text', output_parser=StrOutputParser(), return_final_only=True, llm_kwargs={}), get_input=<function default_get_input at 0x7fd6ed1bb910>), base_retriever=VectorStoreRetriever(tags=['Chroma', 'OpenAIEmbeddings'], metadata=None, vectorstore=<langchain.vectorstores.chroma.Chroma object at 0x7fd6ed1b3f40>, search_type='mmr', search_kwargs={})),\n",
       "  'self_query_retriever': SelfQueryRetriever(tags=None, metadata=None, vectorstore=<langchain.vectorstores.chroma.Chroma object at 0x7fd6ed1b3f40>, llm_chain=LLMChain(memory=None, callbacks=None, callback_manager=None, verbose=False, tags=None, metadata=None, prompt=FewShotPromptTemplate(input_variables=['query'], output_parser=StructuredQueryOutputParser(ast_parse=<bound method Lark.parse of Lark(open('<string>'), parser='lalr', lexer='contextual', ...)>), partial_variables={}, examples=[{'i': 1, 'data_source': '```json\\n{{\\n    \"content\": \"Lyrics of a song\",\\n    \"attributes\": {{\\n        \"artist\": {{\\n            \"type\": \"string\",\\n            \"description\": \"Name of the song artist\"\\n        }},\\n        \"length\": {{\\n            \"type\": \"integer\",\\n            \"description\": \"Length of the song in seconds\"\\n        }},\\n        \"genre\": {{\\n            \"type\": \"string\",\\n            \"description\": \"The song genre, one of \"pop\", \"rock\" or \"rap\"\"\\n        }}\\n    }}\\n}}\\n```', 'user_query': 'What are songs by Taylor Swift or Katy Perry about teenage romance under 3 minutes long in the dance pop genre', 'structured_request': '```json\\n{{\\n    \"query\": \"teenager love\",\\n    \"filter\": \"and(or(eq(\\\\\"artist\\\\\", \\\\\"Taylor Swift\\\\\"), eq(\\\\\"artist\\\\\", \\\\\"Katy Perry\\\\\")), lt(\\\\\"length\\\\\", 180), eq(\\\\\"genre\\\\\", \\\\\"pop\\\\\"))\"\\n}}\\n```'}, {'i': 2, 'data_source': '```json\\n{{\\n    \"content\": \"Lyrics of a song\",\\n    \"attributes\": {{\\n        \"artist\": {{\\n            \"type\": \"string\",\\n            \"description\": \"Name of the song artist\"\\n        }},\\n        \"length\": {{\\n            \"type\": \"integer\",\\n            \"description\": \"Length of the song in seconds\"\\n        }},\\n        \"genre\": {{\\n            \"type\": \"string\",\\n            \"description\": \"The song genre, one of \"pop\", \"rock\" or \"rap\"\"\\n        }}\\n    }}\\n}}\\n```', 'user_query': 'What are songs that were not published on Spotify', 'structured_request': '```json\\n{{\\n    \"query\": \"\",\\n    \"filter\": \"NO_FILTER\"\\n}}\\n```'}], example_selector=None, validate_template=True, example_prompt=PromptTemplate(input_variables=['i', 'data_source', 'user_query', 'structured_request'], output_parser=None, partial_variables={}, template='<< Example {i}. >>\\nData Source:\\n{data_source}\\n\\nUser Query:\\n{user_query}\\n\\nStructured Request:\\n{structured_request}\\n', template_format='f-string', validate_template=True), suffix='<< Example 3. >>\\nData Source:\\n```json\\n{{\\n    \"content\": \"Document content\",\\n    \"attributes\": {{\\n    \"category\": {{\\n        \"description\": \"Category of te text content - possible values are NarrativeText and Title\",\\n        \"type\": \"string\"\\n    }},\\n    \"date\": {{\\n        \"description\": \"Date when the document was published\",\\n        \"type\": \"string\"\\n    }},\\n    \"filename\": {{\\n        \"description\": \"Name of the file\",\\n        \"type\": \"string\"\\n    }},\\n    \"id\": {{\\n        \"description\": \"Document ID\",\\n        \"type\": \"string\"\\n    }},\\n    \"page_number\": {{\\n        \"description\": \"Page number from the original document\",\\n        \"type\": \"string\"\\n    }},\\n    \"register_num\": {{\\n        \"description\": \"Patent registration number\",\\n        \"type\": \"string\"\\n    }},\\n    \"source\": {{\\n        \"description\": \"Source that published the document\",\\n        \"type\": \"string\"\\n    }},\\n    \"title\": {{\\n        \"description\": \"Document title\",\\n        \"type\": \"string\"\\n    }},\\n    \"type\": {{\\n        \"description\": \"Type of the document - possible value are article, lecture and patent\",\\n        \"type\": \"string\"\\n    }}\\n}}\\n}}\\n```\\n\\nUser Query:\\n{query}\\n\\nStructured Request:\\n', example_separator='\\n\\n', prefix='Your goal is to structure the user\\'s query to match the request schema provided below.\\n\\n<< Structured Request Schema >>\\nWhen responding use a markdown code snippet with a JSON object formatted in the following schema:\\n\\n```json\\n{{\\n    \"query\": string \\\\ text string to compare to document contents\\n    \"filter\": string \\\\ logical condition statement for filtering documents\\n}}\\n```\\n\\nThe query string should contain only text that is expected to match the contents of documents. Any conditions in the filter should not be mentioned in the query as well.\\n\\nA logical condition statement is composed of one or more comparison and logical operation statements.\\n\\nA comparison statement takes the form: `comp(attr, val)`:\\n- `comp` (eq | gt | gte | lt | lte): comparator\\n- `attr` (string):  name of attribute to apply the comparison to\\n- `val` (string): is the comparison value\\n\\nA logical operation statement takes the form `op(statement1, statement2, ...)`:\\n- `op` (and | or): logical operator\\n- `statement1`, `statement2`, ... (comparison statements or logical operation statements): one or more statements to apply the operation to\\n\\nMake sure that you only use the comparators and logical operators listed above and no others.\\nMake sure that filters only refer to attributes that exist in the data source.\\nMake sure that filters only use the attributed names with its function names if there are functions applied on them.\\nMake sure that filters only use format `YYYY-MM-DD` when handling timestamp data typed values.\\nMake sure that filters take into account the descriptions of attributes and only make comparisons that are feasible given the type of data being stored.\\nMake sure that filters are only used as needed. If there are no filters that should be applied return \"NO_FILTER\" for the filter value.', template_format='f-string'), llm=ChatOpenAI(cache=None, verbose=False, callbacks=None, callback_manager=None, tags=None, metadata=None, client=<class 'openai.api_resources.chat_completion.ChatCompletion'>, model_name='gpt-3.5-turbo', temperature=0.0, model_kwargs={}, openai_api_key='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', openai_api_base='', openai_organization='', openai_proxy='', request_timeout=None, max_retries=6, streaming=False, n=1, max_tokens=None, tiktoken_model_name=None), output_key='text', output_parser=StrOutputParser(), return_final_only=True, llm_kwargs={}), search_type='similarity', search_kwargs={}, structured_query_translator=<langchain.retrievers.self_query.chroma.ChromaTranslator object at 0x7fd694383520>, verbose=True, use_original_query=False),\n",
       "  'ensemble_retriever': EnsembleRetriever(tags=None, metadata=None, retrievers=[VectorStoreRetriever(tags=['Chroma', 'OpenAIEmbeddings'], metadata=None, vectorstore=<langchain.vectorstores.chroma.Chroma object at 0x7fd6ed1b3f40>, search_type='mmr', search_kwargs={}), MultiQueryRetriever(tags=None, metadata=None, retriever=VectorStoreRetriever(tags=['Chroma', 'OpenAIEmbeddings'], metadata=None, vectorstore=<langchain.vectorstores.chroma.Chroma object at 0x7fd6ed1b3f40>, search_type='mmr', search_kwargs={}), llm_chain=LLMChain(memory=None, callbacks=None, callback_manager=None, verbose=False, tags=None, metadata=None, prompt=PromptTemplate(input_variables=['question'], output_parser=None, partial_variables={}, template='You are an AI language model assistant. Your task is \\n    to generate 3 different versions of the given user \\n    question to retrieve relevant documents from a vector  database. \\n    By generating multiple perspectives on the user question, \\n    your goal is to help the user overcome some of the limitations \\n    of distance-based similarity search. Provide these alternative \\n    questions separated by newlines. Original question: {question}', template_format='f-string', validate_template=True), llm=ChatOpenAI(cache=None, verbose=False, callbacks=None, callback_manager=None, tags=None, metadata=None, client=<class 'openai.api_resources.chat_completion.ChatCompletion'>, model_name='gpt-3.5-turbo', temperature=0.0, model_kwargs={}, openai_api_key='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', openai_api_base='', openai_organization='', openai_proxy='', request_timeout=None, max_retries=6, streaming=False, n=1, max_tokens=None, tiktoken_model_name=None), output_key='text', output_parser=LineListOutputParser(pydantic_object=<class 'langchain.retrievers.multi_query.LineList'>), return_final_only=True, llm_kwargs={}), verbose=True, parser_key='lines'), ContextualCompressionRetriever(tags=None, metadata=None, base_compressor=LLMChainExtractor(llm_chain=LLMChain(memory=None, callbacks=None, callback_manager=None, verbose=False, tags=None, metadata=None, prompt=PromptTemplate(input_variables=['question', 'context'], output_parser=NoOutputParser(no_output_str='NO_OUTPUT'), partial_variables={}, template='Given the following question and context, extract any part of the context *AS IS* that is relevant to answer the question. If none of the context is relevant return NO_OUTPUT. \\n\\nRemember, *DO NOT* edit the extracted parts of the context.\\n\\n> Question: {question}\\n> Context:\\n>>>\\n{context}\\n>>>\\nExtracted relevant parts:', template_format='f-string', validate_template=True), llm=ChatOpenAI(cache=None, verbose=False, callbacks=None, callback_manager=None, tags=None, metadata=None, client=<class 'openai.api_resources.chat_completion.ChatCompletion'>, model_name='gpt-3.5-turbo', temperature=0.0, model_kwargs={}, openai_api_key='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', openai_api_base='', openai_organization='', openai_proxy='', request_timeout=None, max_retries=6, streaming=False, n=1, max_tokens=None, tiktoken_model_name=None), output_key='text', output_parser=StrOutputParser(), return_final_only=True, llm_kwargs={}), get_input=<function default_get_input at 0x7fd6ed1bb910>), base_retriever=VectorStoreRetriever(tags=['Chroma', 'OpenAIEmbeddings'], metadata=None, vectorstore=<langchain.vectorstores.chroma.Chroma object at 0x7fd6ed1b3f40>, search_type='mmr', search_kwargs={})), SelfQueryRetriever(tags=None, metadata=None, vectorstore=<langchain.vectorstores.chroma.Chroma object at 0x7fd6ed1b3f40>, llm_chain=LLMChain(memory=None, callbacks=None, callback_manager=None, verbose=False, tags=None, metadata=None, prompt=FewShotPromptTemplate(input_variables=['query'], output_parser=StructuredQueryOutputParser(ast_parse=<bound method Lark.parse of Lark(open('<string>'), parser='lalr', lexer='contextual', ...)>), partial_variables={}, examples=[{'i': 1, 'data_source': '```json\\n{{\\n    \"content\": \"Lyrics of a song\",\\n    \"attributes\": {{\\n        \"artist\": {{\\n            \"type\": \"string\",\\n            \"description\": \"Name of the song artist\"\\n        }},\\n        \"length\": {{\\n            \"type\": \"integer\",\\n            \"description\": \"Length of the song in seconds\"\\n        }},\\n        \"genre\": {{\\n            \"type\": \"string\",\\n            \"description\": \"The song genre, one of \"pop\", \"rock\" or \"rap\"\"\\n        }}\\n    }}\\n}}\\n```', 'user_query': 'What are songs by Taylor Swift or Katy Perry about teenage romance under 3 minutes long in the dance pop genre', 'structured_request': '```json\\n{{\\n    \"query\": \"teenager love\",\\n    \"filter\": \"and(or(eq(\\\\\"artist\\\\\", \\\\\"Taylor Swift\\\\\"), eq(\\\\\"artist\\\\\", \\\\\"Katy Perry\\\\\")), lt(\\\\\"length\\\\\", 180), eq(\\\\\"genre\\\\\", \\\\\"pop\\\\\"))\"\\n}}\\n```'}, {'i': 2, 'data_source': '```json\\n{{\\n    \"content\": \"Lyrics of a song\",\\n    \"attributes\": {{\\n        \"artist\": {{\\n            \"type\": \"string\",\\n            \"description\": \"Name of the song artist\"\\n        }},\\n        \"length\": {{\\n            \"type\": \"integer\",\\n            \"description\": \"Length of the song in seconds\"\\n        }},\\n        \"genre\": {{\\n            \"type\": \"string\",\\n            \"description\": \"The song genre, one of \"pop\", \"rock\" or \"rap\"\"\\n        }}\\n    }}\\n}}\\n```', 'user_query': 'What are songs that were not published on Spotify', 'structured_request': '```json\\n{{\\n    \"query\": \"\",\\n    \"filter\": \"NO_FILTER\"\\n}}\\n```'}], example_selector=None, validate_template=True, example_prompt=PromptTemplate(input_variables=['i', 'data_source', 'user_query', 'structured_request'], output_parser=None, partial_variables={}, template='<< Example {i}. >>\\nData Source:\\n{data_source}\\n\\nUser Query:\\n{user_query}\\n\\nStructured Request:\\n{structured_request}\\n', template_format='f-string', validate_template=True), suffix='<< Example 3. >>\\nData Source:\\n```json\\n{{\\n    \"content\": \"Document content\",\\n    \"attributes\": {{\\n    \"category\": {{\\n        \"description\": \"Category of te text content - possible values are NarrativeText and Title\",\\n        \"type\": \"string\"\\n    }},\\n    \"date\": {{\\n        \"description\": \"Date when the document was published\",\\n        \"type\": \"string\"\\n    }},\\n    \"filename\": {{\\n        \"description\": \"Name of the file\",\\n        \"type\": \"string\"\\n    }},\\n    \"id\": {{\\n        \"description\": \"Document ID\",\\n        \"type\": \"string\"\\n    }},\\n    \"page_number\": {{\\n        \"description\": \"Page number from the original document\",\\n        \"type\": \"string\"\\n    }},\\n    \"register_num\": {{\\n        \"description\": \"Patent registration number\",\\n        \"type\": \"string\"\\n    }},\\n    \"source\": {{\\n        \"description\": \"Source that published the document\",\\n        \"type\": \"string\"\\n    }},\\n    \"title\": {{\\n        \"description\": \"Document title\",\\n        \"type\": \"string\"\\n    }},\\n    \"type\": {{\\n        \"description\": \"Type of the document - possible value are article, lecture and patent\",\\n        \"type\": \"string\"\\n    }}\\n}}\\n}}\\n```\\n\\nUser Query:\\n{query}\\n\\nStructured Request:\\n', example_separator='\\n\\n', prefix='Your goal is to structure the user\\'s query to match the request schema provided below.\\n\\n<< Structured Request Schema >>\\nWhen responding use a markdown code snippet with a JSON object formatted in the following schema:\\n\\n```json\\n{{\\n    \"query\": string \\\\ text string to compare to document contents\\n    \"filter\": string \\\\ logical condition statement for filtering documents\\n}}\\n```\\n\\nThe query string should contain only text that is expected to match the contents of documents. Any conditions in the filter should not be mentioned in the query as well.\\n\\nA logical condition statement is composed of one or more comparison and logical operation statements.\\n\\nA comparison statement takes the form: `comp(attr, val)`:\\n- `comp` (eq | gt | gte | lt | lte): comparator\\n- `attr` (string):  name of attribute to apply the comparison to\\n- `val` (string): is the comparison value\\n\\nA logical operation statement takes the form `op(statement1, statement2, ...)`:\\n- `op` (and | or): logical operator\\n- `statement1`, `statement2`, ... (comparison statements or logical operation statements): one or more statements to apply the operation to\\n\\nMake sure that you only use the comparators and logical operators listed above and no others.\\nMake sure that filters only refer to attributes that exist in the data source.\\nMake sure that filters only use the attributed names with its function names if there are functions applied on them.\\nMake sure that filters only use format `YYYY-MM-DD` when handling timestamp data typed values.\\nMake sure that filters take into account the descriptions of attributes and only make comparisons that are feasible given the type of data being stored.\\nMake sure that filters are only used as needed. If there are no filters that should be applied return \"NO_FILTER\" for the filter value.', template_format='f-string'), llm=ChatOpenAI(cache=None, verbose=False, callbacks=None, callback_manager=None, tags=None, metadata=None, client=<class 'openai.api_resources.chat_completion.ChatCompletion'>, model_name='gpt-3.5-turbo', temperature=0.0, model_kwargs={}, openai_api_key='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', openai_api_base='', openai_organization='', openai_proxy='', request_timeout=None, max_retries=6, streaming=False, n=1, max_tokens=None, tiktoken_model_name=None), output_key='text', output_parser=StrOutputParser(), return_final_only=True, llm_kwargs={}), search_type='similarity', search_kwargs={}, structured_query_translator=<langchain.retrievers.self_query.chroma.ChromaTranslator object at 0x7fd694383520>, verbose=True, use_original_query=False), EnsembleRetriever(tags=None, metadata=None, retrievers=[VectorStoreRetriever(tags=['Chroma', 'OpenAIEmbeddings'], metadata=None, vectorstore=<langchain.vectorstores.chroma.Chroma object at 0x7fd6ed1b3f40>, search_type='mmr', search_kwargs={}), MultiQueryRetriever(tags=None, metadata=None, retriever=VectorStoreRetriever(tags=['Chroma', 'OpenAIEmbeddings'], metadata=None, vectorstore=<langchain.vectorstores.chroma.Chroma object at 0x7fd6ed1b3f40>, search_type='mmr', search_kwargs={}), llm_chain=LLMChain(memory=None, callbacks=None, callback_manager=None, verbose=False, tags=None, metadata=None, prompt=PromptTemplate(input_variables=['question'], output_parser=None, partial_variables={}, template='You are an AI language model assistant. Your task is \\n    to generate 3 different versions of the given user \\n    question to retrieve relevant documents from a vector  database. \\n    By generating multiple perspectives on the user question, \\n    your goal is to help the user overcome some of the limitations \\n    of distance-based similarity search. Provide these alternative \\n    questions separated by newlines. Original question: {question}', template_format='f-string', validate_template=True), llm=ChatOpenAI(cache=None, verbose=False, callbacks=None, callback_manager=None, tags=None, metadata=None, client=<class 'openai.api_resources.chat_completion.ChatCompletion'>, model_name='gpt-3.5-turbo', temperature=0.0, model_kwargs={}, openai_api_key='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', openai_api_base='', openai_organization='', openai_proxy='', request_timeout=None, max_retries=6, streaming=False, n=1, max_tokens=None, tiktoken_model_name=None), output_key='text', output_parser=LineListOutputParser(pydantic_object=<class 'langchain.retrievers.multi_query.LineList'>), return_final_only=True, llm_kwargs={}), verbose=True, parser_key='lines'), ContextualCompressionRetriever(tags=None, metadata=None, base_compressor=LLMChainExtractor(llm_chain=LLMChain(memory=None, callbacks=None, callback_manager=None, verbose=False, tags=None, metadata=None, prompt=PromptTemplate(input_variables=['question', 'context'], output_parser=NoOutputParser(no_output_str='NO_OUTPUT'), partial_variables={}, template='Given the following question and context, extract any part of the context *AS IS* that is relevant to answer the question. If none of the context is relevant return NO_OUTPUT. \\n\\nRemember, *DO NOT* edit the extracted parts of the context.\\n\\n> Question: {question}\\n> Context:\\n>>>\\n{context}\\n>>>\\nExtracted relevant parts:', template_format='f-string', validate_template=True), llm=ChatOpenAI(cache=None, verbose=False, callbacks=None, callback_manager=None, tags=None, metadata=None, client=<class 'openai.api_resources.chat_completion.ChatCompletion'>, model_name='gpt-3.5-turbo', temperature=0.0, model_kwargs={}, openai_api_key='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', openai_api_base='', openai_organization='', openai_proxy='', request_timeout=None, max_retries=6, streaming=False, n=1, max_tokens=None, tiktoken_model_name=None), output_key='text', output_parser=StrOutputParser(), return_final_only=True, llm_kwargs={}), get_input=<function default_get_input at 0x7fd6ed1bb910>), base_retriever=VectorStoreRetriever(tags=['Chroma', 'OpenAIEmbeddings'], metadata=None, vectorstore=<langchain.vectorstores.chroma.Chroma object at 0x7fd6ed1b3f40>, search_type='mmr', search_kwargs={})), SelfQueryRetriever(tags=None, metadata=None, vectorstore=<langchain.vectorstores.chroma.Chroma object at 0x7fd6ed1b3f40>, llm_chain=LLMChain(memory=None, callbacks=None, callback_manager=None, verbose=False, tags=None, metadata=None, prompt=FewShotPromptTemplate(input_variables=['query'], output_parser=StructuredQueryOutputParser(ast_parse=<bound method Lark.parse of Lark(open('<string>'), parser='lalr', lexer='contextual', ...)>), partial_variables={}, examples=[{'i': 1, 'data_source': '```json\\n{{\\n    \"content\": \"Lyrics of a song\",\\n    \"attributes\": {{\\n        \"artist\": {{\\n            \"type\": \"string\",\\n            \"description\": \"Name of the song artist\"\\n        }},\\n        \"length\": {{\\n            \"type\": \"integer\",\\n            \"description\": \"Length of the song in seconds\"\\n        }},\\n        \"genre\": {{\\n            \"type\": \"string\",\\n            \"description\": \"The song genre, one of \"pop\", \"rock\" or \"rap\"\"\\n        }}\\n    }}\\n}}\\n```', 'user_query': 'What are songs by Taylor Swift or Katy Perry about teenage romance under 3 minutes long in the dance pop genre', 'structured_request': '```json\\n{{\\n    \"query\": \"teenager love\",\\n    \"filter\": \"and(or(eq(\\\\\"artist\\\\\", \\\\\"Taylor Swift\\\\\"), eq(\\\\\"artist\\\\\", \\\\\"Katy Perry\\\\\")), lt(\\\\\"length\\\\\", 180), eq(\\\\\"genre\\\\\", \\\\\"pop\\\\\"))\"\\n}}\\n```'}, {'i': 2, 'data_source': '```json\\n{{\\n    \"content\": \"Lyrics of a song\",\\n    \"attributes\": {{\\n        \"artist\": {{\\n            \"type\": \"string\",\\n            \"description\": \"Name of the song artist\"\\n        }},\\n        \"length\": {{\\n            \"type\": \"integer\",\\n            \"description\": \"Length of the song in seconds\"\\n        }},\\n        \"genre\": {{\\n            \"type\": \"string\",\\n            \"description\": \"The song genre, one of \"pop\", \"rock\" or \"rap\"\"\\n        }}\\n    }}\\n}}\\n```', 'user_query': 'What are songs that were not published on Spotify', 'structured_request': '```json\\n{{\\n    \"query\": \"\",\\n    \"filter\": \"NO_FILTER\"\\n}}\\n```'}], example_selector=None, validate_template=True, example_prompt=PromptTemplate(input_variables=['i', 'data_source', 'user_query', 'structured_request'], output_parser=None, partial_variables={}, template='<< Example {i}. >>\\nData Source:\\n{data_source}\\n\\nUser Query:\\n{user_query}\\n\\nStructured Request:\\n{structured_request}\\n', template_format='f-string', validate_template=True), suffix='<< Example 3. >>\\nData Source:\\n```json\\n{{\\n    \"content\": \"Document content\",\\n    \"attributes\": {{\\n    \"category\": {{\\n        \"description\": \"Category of te text content - possible values are NarrativeText and Title\",\\n        \"type\": \"string\"\\n    }},\\n    \"date\": {{\\n        \"description\": \"Date when the document was published\",\\n        \"type\": \"string\"\\n    }},\\n    \"filename\": {{\\n        \"description\": \"Name of the file\",\\n        \"type\": \"string\"\\n    }},\\n    \"id\": {{\\n        \"description\": \"Document ID\",\\n        \"type\": \"string\"\\n    }},\\n    \"page_number\": {{\\n        \"description\": \"Page number from the original document\",\\n        \"type\": \"string\"\\n    }},\\n    \"register_num\": {{\\n        \"description\": \"Patent registration number\",\\n        \"type\": \"string\"\\n    }},\\n    \"source\": {{\\n        \"description\": \"Source that published the document\",\\n        \"type\": \"string\"\\n    }},\\n    \"title\": {{\\n        \"description\": \"Document title\",\\n        \"type\": \"string\"\\n    }},\\n    \"type\": {{\\n        \"description\": \"Type of the document - possible value are article, lecture and patent\",\\n        \"type\": \"string\"\\n    }}\\n}}\\n}}\\n```\\n\\nUser Query:\\n{query}\\n\\nStructured Request:\\n', example_separator='\\n\\n', prefix='Your goal is to structure the user\\'s query to match the request schema provided below.\\n\\n<< Structured Request Schema >>\\nWhen responding use a markdown code snippet with a JSON object formatted in the following schema:\\n\\n```json\\n{{\\n    \"query\": string \\\\ text string to compare to document contents\\n    \"filter\": string \\\\ logical condition statement for filtering documents\\n}}\\n```\\n\\nThe query string should contain only text that is expected to match the contents of documents. Any conditions in the filter should not be mentioned in the query as well.\\n\\nA logical condition statement is composed of one or more comparison and logical operation statements.\\n\\nA comparison statement takes the form: `comp(attr, val)`:\\n- `comp` (eq | gt | gte | lt | lte): comparator\\n- `attr` (string):  name of attribute to apply the comparison to\\n- `val` (string): is the comparison value\\n\\nA logical operation statement takes the form `op(statement1, statement2, ...)`:\\n- `op` (and | or): logical operator\\n- `statement1`, `statement2`, ... (comparison statements or logical operation statements): one or more statements to apply the operation to\\n\\nMake sure that you only use the comparators and logical operators listed above and no others.\\nMake sure that filters only refer to attributes that exist in the data source.\\nMake sure that filters only use the attributed names with its function names if there are functions applied on them.\\nMake sure that filters only use format `YYYY-MM-DD` when handling timestamp data typed values.\\nMake sure that filters take into account the descriptions of attributes and only make comparisons that are feasible given the type of data being stored.\\nMake sure that filters are only used as needed. If there are no filters that should be applied return \"NO_FILTER\" for the filter value.', template_format='f-string'), llm=ChatOpenAI(cache=None, verbose=False, callbacks=None, callback_manager=None, tags=None, metadata=None, client=<class 'openai.api_resources.chat_completion.ChatCompletion'>, model_name='gpt-3.5-turbo', temperature=0.0, model_kwargs={}, openai_api_key='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', openai_api_base='', openai_organization='', openai_proxy='', request_timeout=None, max_retries=6, streaming=False, n=1, max_tokens=None, tiktoken_model_name=None), output_key='text', output_parser=StrOutputParser(), return_final_only=True, llm_kwargs={}), search_type='similarity', search_kwargs={}, structured_query_translator=<langchain.retrievers.self_query.chroma.ChromaTranslator object at 0x7fd696a99930>, verbose=True, use_original_query=False)], weights=[0.25, 0.25, 0.25, 0.25], c=60)], weights=[0.2, 0.2, 0.2, 0.2, 0.2], c=60)}}"
      ]
     },
     "execution_count": 23,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "all_retrievers"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "q = \"\"\"Use the following pieces of context to answer the question at the end.\n",
    "If you don't know the answer, just say that you don't know, don't try to\n",
    "make up an answer.\n",
    "\n",
    "{context} // i.e the pdf text content\n",
    "\n",
    "Question: {query} // i.e our actualy query, 'Who is the CV about?'\n",
    "Helpful Answer:\"\"\""
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "base",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.9"
  },
  "orig_nbformat": 4
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
