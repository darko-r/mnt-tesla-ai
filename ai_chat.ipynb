{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 81,
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "import openai\n",
    "import copy\n",
    "\n",
    "from langchain.embeddings import OpenAIEmbeddings\n",
    "from langchain.chat_models import ChatOpenAI\n",
    "\n",
    "\n",
    "embeddings = OpenAIEmbeddings()\n",
    "llm_name = \"gpt-3.5-turbo\"\n",
    "llm = ChatOpenAI(model_name = llm_name, temperature = 0)\n",
    "\n",
    "def get_completion(prompt, model = llm_name, temperature = 0):\n",
    "    messages = [{\"role\": \"user\", \"content\": prompt}]\n",
    "    response = openai.ChatCompletion.create(model = model,\n",
    "                                            messages = messages,\n",
    "                                            temperature = temperature)\n",
    "    return response.choices[0].message['content']\n",
    "\n",
    "# document folders\n",
    "folder_names = [\"articles\", \"patents\", \"lectures\"]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 82,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Could not convert document The Moon's Rotation 2.docx from articles\n"
     ]
    }
   ],
   "source": [
    "# Converting Docx to Pdf for easier loading\n",
    "\n",
    "import aspose.words as aw\n",
    "\n",
    "for folder_name in folder_names:\n",
    "    os.system(f\"rm pdf_docs/{folder_name}/*.pdf\")\n",
    "\n",
    "    for file_name in os.listdir(os.path.join('docx_docs', folder_name)):\n",
    "        try:\n",
    "            a = aw.Document(os.path.join('docx_docs', folder_name, file_name))\n",
    "            new_filename = ''.join(file_name.rsplit('.', 1)[:-1]) + '.pdf'\n",
    "            a.save(os.path.join('pdf_docs', folder_name, new_filename))\n",
    "        except:\n",
    "            print(f\"Could not convert document {file_name} from {folder_name}\")\n",
    "\n",
    "# TODO: Investigate why The Moon's Rotation 2.docx cannot be converted\n",
    "os.remove(\"pdf_docs/articles/The Moon's Rotation 2.pdf\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 129,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Loading PDF documents\n",
    "\n",
    "from langchain.document_loaders import PyPDFDirectoryLoader\n",
    "from langchain.text_splitter import RecursiveCharacterTextSplitter\n",
    "\n",
    "# pages_dict = {}\n",
    "pages = []\n",
    "text_splitter = RecursiveCharacterTextSplitter(chunk_size = 10000, chunk_overlap = 1000)\n",
    "for folder_name in folder_names:\n",
    "    loader = PyPDFDirectoryLoader(path = f\"pdf_docs/{folder_name}/\")\n",
    "    # TODO: Try other values for the text splitter chunk_size and chunk_overlap\n",
    "    # TODO: Load without page splitting\n",
    "    pages += loader.load_and_split(text_splitter = text_splitter)\n",
    "    # pages_dict[folder_name] = loader.load_and_split(text_splitter = text_splitter)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 130,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Removing watermarks from the data\n",
    "\n",
    "strings_to_remove = ['Evaluation Only. Created with Aspose.Words. Copyright 2003-2023 Aspose Pty \\nLtd.',\n",
    "                    'Evaluation Only. Created with Aspose.Words. Copyright 2003-2023 Aspose Pty Ltd.',\n",
    "                    'Evaluation Only. Created with Aspose.Words. Copyright 2003-2023 Aspose Pty',\n",
    "                    'Created with an evaluation copy of Aspose.Words. To discover the full versions \\nof our APIs please visit: https://products.aspose.com/words/',\n",
    "                    'Created with an evaluation copy of Aspose.Words. To discover the full versions',\n",
    "                    'Created with an evaluation copy of Aspose.Words. To discover the full \\nversions of our APIs please visit: https://products.aspose.com/words/',\n",
    "                    'Created with an evaluation copy of Aspose.Words. To discover the full versions of our \\nAPIs please visit: https://products.aspose.com/words/',\n",
    "                    'of our APIs please visit: https://products.aspose.com/words/',\n",
    "                    'Created with an evaluation copy of Aspose.Words. To discover the \\nfull versions of our APIs please visit: \\nhttps://products.aspose.com/words/Evaluation',\n",
    "                    'Only. Created with Aspose.Words. Copyright 2003-2023 \\nAspose Pty Ltd.',\n",
    "                    'Created with an evaluation copy of Aspose.Words. To discover the',\n",
    "                    'full versions of our APIs please visit: \\nhttps://products.aspose.com/words/',\n",
    "                    ' of our \\nAPIs please visit: https://products.aspose.com/words/'\n",
    "                    ]\n",
    "\n",
    "for i, page in enumerate(pages):\n",
    "    for string in strings_to_remove:\n",
    "        page.page_content = page.page_content.replace(string, '')\n",
    "    assert not 'Created with Aspose' in page.page_content, f\"Assert failed for page number {i} with content: {page.page_content} from file {page.metadata}\"\n",
    "    assert not 'Aspose' in page.page_content, f\"Assert failed for page number {i} with content: {page.page_content} from file {page.metadata}\"\n",
    "    assert not 'Evaluation Only' in page.page_content, f\"Assert failed for page number {i} with content: {page.page_content} from file {page.metadata}\"\n",
    "    assert not 'Copyright' in page.page_content, f\"Assert failed for page number {i} with content: {page.page_content} from file {page.metadata}\"\n",
    "    assert not 'https://products.aspose.com/words/' in page.page_content, f\"Assert failed for page number {i} with content: {page.page_content} from file {page.metadata}\"\n",
    "\n",
    "    page.metadata['document_name'] = ''.join(page.metadata['source'].split('/')[-1].rsplit('.', 1)[0])\n",
    "    del page.metadata['source']\n",
    "\n",
    "pages_backup = copy.deepcopy(pages)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 151,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Refresh pages\n",
    "\n",
    "pages = copy.deepcopy(pages_backup)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 152,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Metadata parsing\n",
    "\n",
    "import json\n",
    "import string\n",
    "\n",
    "ascii_replace_dict = {'â€™': '’', 'â€œ': '“', 'â€': '”'}\n",
    "def replace_non_ascii(s):\n",
    "    for pair_k, pair_v in ascii_replace_dict.items():\n",
    "        s = s.replace(pair_k, pair_v)\n",
    "    return s\n",
    "\n",
    "metadata_dict = {}\n",
    "metadatas = json.load(open('metadata.json'))\n",
    "\n",
    "for metadata in metadatas[2]['data']:\n",
    "    if metadata['id'] in ['228', '413']:\n",
    "        # These are duplicates, not needed\n",
    "        continue\n",
    "    key = ''.join(metadata['file_url'].split('/')[-1].rsplit('.', 1)[:-1])\n",
    "    \n",
    "    # Repalce non-ascii characters in key\n",
    "    key = replace_non_ascii(key)\n",
    "    \n",
    "    # Make sure that there are no duplicate entries for the same document type\n",
    "    if (key in metadata_dict.keys() and metadata['type'] == metadata_dict[key]['type']):\n",
    "        print(key)\n",
    "        print(metadata['id'])\n",
    "    assert not (key in metadata_dict.keys() and metadata['type'] == metadata_dict[key]['type'])\n",
    "    metadata_dict[key] = {key: value for key, value in metadata.items() if value is not None}\n",
    "\n",
    "    # Replace non-ascii characters in file url\n",
    "    # metadata_dict[key]['file_url'] = replace_non_ascii(metadata_dict[key]['file_url'])\n",
    "    del metadata_dict[key]['file_url']\n",
    "    for m_key, m_value in metadata_dict.items():\n",
    "        if m_value is None:\n",
    "            del metadata_dict[m_key]\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 153,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Adding metadata\n",
    "\n",
    "for page in pages:\n",
    "    assert page.metadata['document_name'] in metadata_dict.keys()\n",
    "    page.metadata.update(metadata_dict[page.metadata['document_name']])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 155,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'page': 0,\n",
       " 'document_name': 'Dr. Tesla Writes of Various Phases of His Discovery',\n",
       " 'id': '150',\n",
       " 'title': 'Dr. Tesla Writes of Various Phases of His Discovery',\n",
       " 'date': '1932-02-06',\n",
       " 'type': 'article',\n",
       " 'source': 'New York Times',\n",
       " 'register_num': None}"
      ]
     },
     "execution_count": 155,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "pages[0].metadata"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 149,
   "metadata": {},
   "outputs": [
    {
     "ename": "ValueError",
     "evalue": "Expected metadata value to be a str, int, float or bool, got None which is a <class 'NoneType'>\n\nTry filtering complex metadata from the document using langchain.vectorstore.utils.filter_complex_metadata.",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mValueError\u001b[0m                                Traceback (most recent call last)",
      "File \u001b[0;32m~/miniconda3/lib/python3.10/site-packages/langchain/vectorstores/chroma.py:209\u001b[0m, in \u001b[0;36mChroma.add_texts\u001b[0;34m(self, texts, metadatas, ids, **kwargs)\u001b[0m\n\u001b[1;32m    208\u001b[0m \u001b[39mtry\u001b[39;00m:\n\u001b[0;32m--> 209\u001b[0m     \u001b[39mself\u001b[39;49m\u001b[39m.\u001b[39;49m_collection\u001b[39m.\u001b[39;49mupsert(\n\u001b[1;32m    210\u001b[0m         metadatas\u001b[39m=\u001b[39;49mmetadatas,\n\u001b[1;32m    211\u001b[0m         embeddings\u001b[39m=\u001b[39;49membeddings_with_metadatas,\n\u001b[1;32m    212\u001b[0m         documents\u001b[39m=\u001b[39;49mtexts_with_metadatas,\n\u001b[1;32m    213\u001b[0m         ids\u001b[39m=\u001b[39;49mids_with_metadata,\n\u001b[1;32m    214\u001b[0m     )\n\u001b[1;32m    215\u001b[0m \u001b[39mexcept\u001b[39;00m \u001b[39mValueError\u001b[39;00m \u001b[39mas\u001b[39;00m e:\n",
      "File \u001b[0;32m~/miniconda3/lib/python3.10/site-packages/chromadb/api/models/Collection.py:294\u001b[0m, in \u001b[0;36mCollection.upsert\u001b[0;34m(self, ids, embeddings, metadatas, documents)\u001b[0m\n\u001b[1;32m    282\u001b[0m \u001b[39m\u001b[39m\u001b[39m\"\"\"Update the embeddings, metadatas or documents for provided ids, or create them if they don't exist.\u001b[39;00m\n\u001b[1;32m    283\u001b[0m \n\u001b[1;32m    284\u001b[0m \u001b[39mArgs:\u001b[39;00m\n\u001b[0;32m   (...)\u001b[0m\n\u001b[1;32m    291\u001b[0m \u001b[39m    None\u001b[39;00m\n\u001b[1;32m    292\u001b[0m \u001b[39m\"\"\"\u001b[39;00m\n\u001b[0;32m--> 294\u001b[0m ids, embeddings, metadatas, documents \u001b[39m=\u001b[39m \u001b[39mself\u001b[39;49m\u001b[39m.\u001b[39;49m_validate_embedding_set(\n\u001b[1;32m    295\u001b[0m     ids, embeddings, metadatas, documents\n\u001b[1;32m    296\u001b[0m )\n\u001b[1;32m    298\u001b[0m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39m_client\u001b[39m.\u001b[39m_upsert(\n\u001b[1;32m    299\u001b[0m     collection_id\u001b[39m=\u001b[39m\u001b[39mself\u001b[39m\u001b[39m.\u001b[39mid,\n\u001b[1;32m    300\u001b[0m     ids\u001b[39m=\u001b[39mids,\n\u001b[0;32m   (...)\u001b[0m\n\u001b[1;32m    303\u001b[0m     documents\u001b[39m=\u001b[39mdocuments,\n\u001b[1;32m    304\u001b[0m )\n",
      "File \u001b[0;32m~/miniconda3/lib/python3.10/site-packages/chromadb/api/models/Collection.py:353\u001b[0m, in \u001b[0;36mCollection._validate_embedding_set\u001b[0;34m(self, ids, embeddings, metadatas, documents, require_embeddings_or_documents)\u001b[0m\n\u001b[1;32m    347\u001b[0m embeddings \u001b[39m=\u001b[39m (\n\u001b[1;32m    348\u001b[0m     validate_embeddings(maybe_cast_one_to_many(embeddings))\n\u001b[1;32m    349\u001b[0m     \u001b[39mif\u001b[39;00m embeddings \u001b[39mis\u001b[39;00m \u001b[39mnot\u001b[39;00m \u001b[39mNone\u001b[39;00m\n\u001b[1;32m    350\u001b[0m     \u001b[39melse\u001b[39;00m \u001b[39mNone\u001b[39;00m\n\u001b[1;32m    351\u001b[0m )\n\u001b[1;32m    352\u001b[0m metadatas \u001b[39m=\u001b[39m (\n\u001b[0;32m--> 353\u001b[0m     validate_metadatas(maybe_cast_one_to_many(metadatas))\n\u001b[1;32m    354\u001b[0m     \u001b[39mif\u001b[39;00m metadatas \u001b[39mis\u001b[39;00m \u001b[39mnot\u001b[39;00m \u001b[39mNone\u001b[39;00m\n\u001b[1;32m    355\u001b[0m     \u001b[39melse\u001b[39;00m \u001b[39mNone\u001b[39;00m\n\u001b[1;32m    356\u001b[0m )\n\u001b[1;32m    357\u001b[0m documents \u001b[39m=\u001b[39m maybe_cast_one_to_many(documents) \u001b[39mif\u001b[39;00m documents \u001b[39mis\u001b[39;00m \u001b[39mnot\u001b[39;00m \u001b[39mNone\u001b[39;00m \u001b[39melse\u001b[39;00m \u001b[39mNone\u001b[39;00m\n",
      "File \u001b[0;32m~/miniconda3/lib/python3.10/site-packages/chromadb/api/types.py:191\u001b[0m, in \u001b[0;36mvalidate_metadatas\u001b[0;34m(metadatas)\u001b[0m\n\u001b[1;32m    190\u001b[0m \u001b[39mfor\u001b[39;00m metadata \u001b[39min\u001b[39;00m metadatas:\n\u001b[0;32m--> 191\u001b[0m     validate_metadata(metadata)\n\u001b[1;32m    192\u001b[0m \u001b[39mreturn\u001b[39;00m metadatas\n",
      "File \u001b[0;32m~/miniconda3/lib/python3.10/site-packages/chromadb/api/types.py:159\u001b[0m, in \u001b[0;36mvalidate_metadata\u001b[0;34m(metadata)\u001b[0m\n\u001b[1;32m    158\u001b[0m     \u001b[39mif\u001b[39;00m \u001b[39mnot\u001b[39;00m \u001b[39misinstance\u001b[39m(value, \u001b[39mbool\u001b[39m) \u001b[39mand\u001b[39;00m \u001b[39mnot\u001b[39;00m \u001b[39misinstance\u001b[39m(value, (\u001b[39mstr\u001b[39m, \u001b[39mint\u001b[39m, \u001b[39mfloat\u001b[39m)):\n\u001b[0;32m--> 159\u001b[0m         \u001b[39mraise\u001b[39;00m \u001b[39mValueError\u001b[39;00m(\n\u001b[1;32m    160\u001b[0m             \u001b[39mf\u001b[39m\u001b[39m\"\u001b[39m\u001b[39mExpected metadata value to be a str, int, float or bool, got \u001b[39m\u001b[39m{\u001b[39;00mvalue\u001b[39m}\u001b[39;00m\u001b[39m which is a \u001b[39m\u001b[39m{\u001b[39;00m\u001b[39mtype\u001b[39m(value)\u001b[39m}\u001b[39;00m\u001b[39m\"\u001b[39m\n\u001b[1;32m    161\u001b[0m         )\n\u001b[1;32m    162\u001b[0m \u001b[39mreturn\u001b[39;00m metadata\n",
      "\u001b[0;31mValueError\u001b[0m: Expected metadata value to be a str, int, float or bool, got None which is a <class 'NoneType'>",
      "\nDuring handling of the above exception, another exception occurred:\n",
      "\u001b[0;31mValueError\u001b[0m                                Traceback (most recent call last)",
      "Cell \u001b[0;32mIn[149], line 5\u001b[0m\n\u001b[1;32m      1\u001b[0m \u001b[39m# Vectorstore creation\u001b[39;00m\n\u001b[1;32m      3\u001b[0m \u001b[39mfrom\u001b[39;00m \u001b[39mlangchain\u001b[39;00m\u001b[39m.\u001b[39;00m\u001b[39mvectorstores\u001b[39;00m \u001b[39mimport\u001b[39;00m Chroma\n\u001b[0;32m----> 5\u001b[0m vectorstore \u001b[39m=\u001b[39m Chroma\u001b[39m.\u001b[39;49mfrom_documents(\n\u001b[1;32m      6\u001b[0m     documents \u001b[39m=\u001b[39;49m pages,\n\u001b[1;32m      7\u001b[0m     embedding \u001b[39m=\u001b[39;49m embeddings,\n\u001b[1;32m      8\u001b[0m     persist_directory\u001b[39m=\u001b[39;49m\u001b[39m\"\u001b[39;49m\u001b[39m./chroma_db\u001b[39;49m\u001b[39m\"\u001b[39;49m\n\u001b[1;32m      9\u001b[0m )\n",
      "File \u001b[0;32m~/miniconda3/lib/python3.10/site-packages/langchain/vectorstores/chroma.py:613\u001b[0m, in \u001b[0;36mChroma.from_documents\u001b[0;34m(cls, documents, embedding, ids, collection_name, persist_directory, client_settings, client, collection_metadata, **kwargs)\u001b[0m\n\u001b[1;32m    611\u001b[0m texts \u001b[39m=\u001b[39m [doc\u001b[39m.\u001b[39mpage_content \u001b[39mfor\u001b[39;00m doc \u001b[39min\u001b[39;00m documents]\n\u001b[1;32m    612\u001b[0m metadatas \u001b[39m=\u001b[39m [doc\u001b[39m.\u001b[39mmetadata \u001b[39mfor\u001b[39;00m doc \u001b[39min\u001b[39;00m documents]\n\u001b[0;32m--> 613\u001b[0m \u001b[39mreturn\u001b[39;00m \u001b[39mcls\u001b[39;49m\u001b[39m.\u001b[39;49mfrom_texts(\n\u001b[1;32m    614\u001b[0m     texts\u001b[39m=\u001b[39;49mtexts,\n\u001b[1;32m    615\u001b[0m     embedding\u001b[39m=\u001b[39;49membedding,\n\u001b[1;32m    616\u001b[0m     metadatas\u001b[39m=\u001b[39;49mmetadatas,\n\u001b[1;32m    617\u001b[0m     ids\u001b[39m=\u001b[39;49mids,\n\u001b[1;32m    618\u001b[0m     collection_name\u001b[39m=\u001b[39;49mcollection_name,\n\u001b[1;32m    619\u001b[0m     persist_directory\u001b[39m=\u001b[39;49mpersist_directory,\n\u001b[1;32m    620\u001b[0m     client_settings\u001b[39m=\u001b[39;49mclient_settings,\n\u001b[1;32m    621\u001b[0m     client\u001b[39m=\u001b[39;49mclient,\n\u001b[1;32m    622\u001b[0m     collection_metadata\u001b[39m=\u001b[39;49mcollection_metadata,\n\u001b[1;32m    623\u001b[0m     \u001b[39m*\u001b[39;49m\u001b[39m*\u001b[39;49mkwargs,\n\u001b[1;32m    624\u001b[0m )\n",
      "File \u001b[0;32m~/miniconda3/lib/python3.10/site-packages/langchain/vectorstores/chroma.py:577\u001b[0m, in \u001b[0;36mChroma.from_texts\u001b[0;34m(cls, texts, embedding, metadatas, ids, collection_name, persist_directory, client_settings, client, collection_metadata, **kwargs)\u001b[0m\n\u001b[1;32m    549\u001b[0m \u001b[39m\u001b[39m\u001b[39m\"\"\"Create a Chroma vectorstore from a raw documents.\u001b[39;00m\n\u001b[1;32m    550\u001b[0m \n\u001b[1;32m    551\u001b[0m \u001b[39mIf a persist_directory is specified, the collection will be persisted there.\u001b[39;00m\n\u001b[0;32m   (...)\u001b[0m\n\u001b[1;32m    566\u001b[0m \u001b[39m    Chroma: Chroma vectorstore.\u001b[39;00m\n\u001b[1;32m    567\u001b[0m \u001b[39m\"\"\"\u001b[39;00m\n\u001b[1;32m    568\u001b[0m chroma_collection \u001b[39m=\u001b[39m \u001b[39mcls\u001b[39m(\n\u001b[1;32m    569\u001b[0m     collection_name\u001b[39m=\u001b[39mcollection_name,\n\u001b[1;32m    570\u001b[0m     embedding_function\u001b[39m=\u001b[39membedding,\n\u001b[0;32m   (...)\u001b[0m\n\u001b[1;32m    575\u001b[0m     \u001b[39m*\u001b[39m\u001b[39m*\u001b[39mkwargs,\n\u001b[1;32m    576\u001b[0m )\n\u001b[0;32m--> 577\u001b[0m chroma_collection\u001b[39m.\u001b[39;49madd_texts(texts\u001b[39m=\u001b[39;49mtexts, metadatas\u001b[39m=\u001b[39;49mmetadatas, ids\u001b[39m=\u001b[39;49mids)\n\u001b[1;32m    578\u001b[0m \u001b[39mreturn\u001b[39;00m chroma_collection\n",
      "File \u001b[0;32m~/miniconda3/lib/python3.10/site-packages/langchain/vectorstores/chroma.py:221\u001b[0m, in \u001b[0;36mChroma.add_texts\u001b[0;34m(self, texts, metadatas, ids, **kwargs)\u001b[0m\n\u001b[1;32m    216\u001b[0m \u001b[39mif\u001b[39;00m \u001b[39m\"\u001b[39m\u001b[39mExpected metadata value to be\u001b[39m\u001b[39m\"\u001b[39m \u001b[39min\u001b[39;00m \u001b[39mstr\u001b[39m(e):\n\u001b[1;32m    217\u001b[0m     msg \u001b[39m=\u001b[39m (\n\u001b[1;32m    218\u001b[0m         \u001b[39m\"\u001b[39m\u001b[39mTry filtering complex metadata from the document using \u001b[39m\u001b[39m\"\u001b[39m\n\u001b[1;32m    219\u001b[0m         \u001b[39m\"\u001b[39m\u001b[39mlangchain.vectorstore.utils.filter_complex_metadata.\u001b[39m\u001b[39m\"\u001b[39m\n\u001b[1;32m    220\u001b[0m     )\n\u001b[0;32m--> 221\u001b[0m     \u001b[39mraise\u001b[39;00m \u001b[39mValueError\u001b[39;00m(e\u001b[39m.\u001b[39margs[\u001b[39m0\u001b[39m] \u001b[39m+\u001b[39m \u001b[39m\"\u001b[39m\u001b[39m\\n\u001b[39;00m\u001b[39m\\n\u001b[39;00m\u001b[39m\"\u001b[39m \u001b[39m+\u001b[39m msg)\n\u001b[1;32m    222\u001b[0m \u001b[39melse\u001b[39;00m:\n\u001b[1;32m    223\u001b[0m     \u001b[39mraise\u001b[39;00m e\n",
      "\u001b[0;31mValueError\u001b[0m: Expected metadata value to be a str, int, float or bool, got None which is a <class 'NoneType'>\n\nTry filtering complex metadata from the document using langchain.vectorstore.utils.filter_complex_metadata."
     ]
    }
   ],
   "source": [
    "# Vectorstore creation\n",
    "\n",
    "from langchain.vectorstores import Chroma\n",
    "\n",
    "vectorstore = Chroma.from_documents(\n",
    "    documents = pages,\n",
    "    embedding = embeddings,\n",
    "    persist_directory=\"./chroma_db\"\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 66,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Vectorstore loading\n",
    "\n",
    "vectorstore = Chroma(persist_directory=\"./chroma_db\", embedding_function = embeddings)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 150,
   "metadata": {},
   "outputs": [
    {
     "ename": "NameError",
     "evalue": "name 'vectorstore' is not defined",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mNameError\u001b[0m                                 Traceback (most recent call last)",
      "Cell \u001b[0;32mIn[150], line 46\u001b[0m\n\u001b[1;32m      4\u001b[0m metadata_field_info \u001b[39m=\u001b[39m [\n\u001b[1;32m      5\u001b[0m     AttributeInfo(\n\u001b[1;32m      6\u001b[0m         name\u001b[39m=\u001b[39m\u001b[39m\"\u001b[39m\u001b[39mdocument_name\u001b[39m\u001b[39m\"\u001b[39m,\n\u001b[0;32m   (...)\u001b[0m\n\u001b[1;32m     39\u001b[0m     )\n\u001b[1;32m     40\u001b[0m ]\n\u001b[1;32m     42\u001b[0m document_content_description \u001b[39m=\u001b[39m \u001b[39m\"\u001b[39m\u001b[39mDocument content\u001b[39m\u001b[39m\"\u001b[39m\n\u001b[1;32m     44\u001b[0m retriever \u001b[39m=\u001b[39m SelfQueryRetriever\u001b[39m.\u001b[39mfrom_llm(\n\u001b[1;32m     45\u001b[0m     llm \u001b[39m=\u001b[39m llm, \n\u001b[0;32m---> 46\u001b[0m     vectorstore \u001b[39m=\u001b[39m vectorstore,\n\u001b[1;32m     47\u001b[0m     document_contents \u001b[39m=\u001b[39m document_content_description,\n\u001b[1;32m     48\u001b[0m     metadata_field_info \u001b[39m=\u001b[39m metadata_field_info, \n\u001b[1;32m     49\u001b[0m     verbose\u001b[39m=\u001b[39m\u001b[39mTrue\u001b[39;00m\n\u001b[1;32m     50\u001b[0m )\n",
      "\u001b[0;31mNameError\u001b[0m: name 'vectorstore' is not defined"
     ]
    }
   ],
   "source": [
    "from langchain.chains.query_constructor.base import AttributeInfo\n",
    "from langchain.retrievers.self_query.base import SelfQueryRetriever\n",
    "\n",
    "metadata_field_info = [\n",
    "    AttributeInfo(\n",
    "        name=\"document_name\",\n",
    "        description=\"Name of the source document\",\n",
    "        type=\"string\",\n",
    "    ),\n",
    "    AttributeInfo(\n",
    "        name=\"id\",\n",
    "        description=\"Document ID\",\n",
    "        type=\"string\",\n",
    "    ),\n",
    "    AttributeInfo(\n",
    "        name=\"title\",\n",
    "        description=\"Title of the document\",\n",
    "        type=\"string\",\n",
    "    ),\n",
    "    AttributeInfo(\n",
    "        name=\"date\",\n",
    "        description=\"When the document was created\",\n",
    "        type=\"string\",\n",
    "    ),\n",
    "    AttributeInfo(\n",
    "        name=\"register_num\",\n",
    "        description=\"Patent registration number\",\n",
    "        type=\"string\",\n",
    "    ),\n",
    "    AttributeInfo(\n",
    "        name=\"source\",\n",
    "        description=\"Source of the document\",\n",
    "        type=\"string\",\n",
    "    ),\n",
    "    AttributeInfo(\n",
    "        name=\"type\",\n",
    "        description=\"Type of the document - options are lecture, article, patent\",\n",
    "        type=\"string\",\n",
    "    )\n",
    "]\n",
    "\n",
    "document_content_description = \"Document content\"\n",
    "\n",
    "retriever = SelfQueryRetriever.from_llm(\n",
    "    llm = llm, \n",
    "    vectorstore = vectorstore,\n",
    "    document_contents = document_content_description,\n",
    "    metadata_field_info = metadata_field_info, \n",
    "    verbose=True\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 73,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/jaksa/miniconda3/lib/python3.10/site-packages/langchain/chains/llm.py:278: UserWarning: The predict_and_parse method is deprecated, instead pass an output parser directly to LLMChain.\n",
      "  warnings.warn(\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "query='Nikola Tesla' filter=Comparison(comparator=<Comparator.EQ: 'eq'>, attribute='document_type', value='lecture') limit=None\n"
     ]
    }
   ],
   "source": [
    "docs = retriever.get_relevant_documents(\"What lectures did Nikola Tesla give\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Basic Retriever example\n",
    "\n",
    "from langchain.chains import RetrievalQA\n",
    "\n",
    "question = \"How many poles shoul my electromotor have, and what should I do if I have the wrong number?\"\n",
    "qa_chain = RetrievalQA.from_chain_type(llm = llm, retriever = retriever)\n",
    "print(qa_chain({\"query\": question}))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 83,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Question: Did Nikola Tesla teach about light?\n",
      "Answer: Yes, Nikola Tesla did discuss light in his lecture. He mentioned the electromagnetic theory of light and expressed his belief that electromagnetic waves, unless they had the frequency of true light waves, could not produce luminous effects. However, he believed that electrostatic waves could excite luminous radiation.\n",
      "Question: When did he give that lecture and where?\n",
      "Answer: Nikola Tesla gave the lecture discussing light at the Ellicot Club in Buffalo on January 12, 1897.\n"
     ]
    }
   ],
   "source": [
    "# Retriever with memory example\n",
    "\n",
    "from langchain.memory import ConversationBufferMemory\n",
    "from langchain.chains import ConversationalRetrievalChain\n",
    "\n",
    "memory = ConversationBufferMemory(memory_key = \"chat_history\", return_messages = True)\n",
    "retriever = vectorstore.as_retriever()\n",
    "qa = ConversationalRetrievalChain.from_llm(llm = llm, retriever = retriever, memory = memory)\n",
    "question = input()\n",
    "print(f\"Question: {question}\")\n",
    "print(f\"Answer: {qa({'question': question})['answer']}\")\n",
    "question = input()\n",
    "print(f\"Question: {question}\")\n",
    "print(f\"Answer: {qa({'question': question})['answer']}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "base",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.9"
  },
  "orig_nbformat": 4
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
